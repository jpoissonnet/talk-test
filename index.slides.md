---
author:
author-twitter:
author-company:
event: Snowcamp
city: Grenoble
date: 23 janvier 2025
---

# Tester c'est tricher

## blank black
> @00:00:00@
> #JP# Dis voir Antoine, tu devrais peut-√™tre leur expliquer pourquoi tu te trimbales avec un parapluie alors qu'il ne pleut pas ici.
> #AC# Tu sais, on n'est jamais trop prudent, imagine il pleut et bien tu ferais pas le malin.
> #JP# T'as pens√© √† porter un K-way dessous, histoire d'√™tre sur ?
> #AC# Malin j'y avais pas trop pens√©...
> Bon aller, on est pas l√† pour √ßa.

## poster main
Tester c'est tricher
==========
Antoine Caron _Engineering Manager @Scaleway_ !
xxxxxxxxxx
xxxxxxxxxx
xxxx
xxxxxxxxxx
xxxxxxxx
==========
xxxxxxxxxx
xxxxxx
------
Jules Poissonnet _Frontend Dev @Bedrock&nbsp;Streaming_
xxxxxxxxxx
xxxxxxxxxx
==========
xxxxxxxxxx
<img src="src/img/grenoble.png"/>
xxxxxxxxxx
xxxxxxxxx
==========
> #AC# Bonjour √† toutes et tous, j'esp√®re que vous allez bien et que cette journ√©e se d√©roule comme vous l'esp√©riez.
> Je m'appelle Antoine Caron et je suis Engineering manager Frontend chez Scaleway, vous m'avez peut-√™tre vu l'ann√©e pass√©e vous parler de Gzip.
> #JP# Et moi c'est Jules Poissonnet, Frontend Dev chez Bedrock Streaming.
> Si l'autre malin et moi-m√™me sommes ici aujourd'hui, c'est pour vous parler de tests.
> C'est un sujet qui nous int√©resse beaucoup et qu'on trouve souvent mal abord√©.
> #AC# On esp√®re avec cette pr√©sentation ouvrir un peu vos chakras sur la notion de testing.

## poster fade-from main
Tester c'est tricher
==========
Antoine Caron _Engineering Manager @Scaleway_ !
xxxxxxxxxx
xxxxxxxxxx
xxxx
xxxxxxxxxx
xxxxxxxx
==========
xxxxxxxxxx
xxxxxx
------
Jules Poissonnet _Frontend Dev @Bedrock&nbsp;Streaming_
xxxxxxxxxx
xxxxxxxxxx
==========
xxxxxxxxxx
<img src="src/img/grenoble.png"/>
xxxxxxxxxx
xxxxxxxxx
==========

> Souvent abord√© de mani√®re dogmatique, on va essayer une approche plus pragmatique
> #JP# Que vous fassiez du frontend, du backend, du mobile ou de l'embarqu√©, des "tests" ou pas, on souhaite vous proposer quelques r√©fl√©xions / conseils et approches qui pourraient √™tre utiles et concr√®tes.
> #AC# Alors pourquoi "Tester c'est tricher", tricher c'est enfreindre des r√®gles √©tablies, des conventions, des normes.
> Pour nous, il existe des normes, des strat√©gies de tests qui sont souvent mal comprises, mal appliqu√©es, mal interpr√©t√©es.
> Certain penseront, qu'√† l'image d'un parapluie qui nous prot√®gent de la pluie, les tests ne servent √† qu'√† nous prot√©ger des bugs et des regressions. On verra ensemble qu'une strat√©gie de tests ne se limite pas qu'√† ce simple besoin.

## blank white 
> @00:01:30@ ¬±00:45
> #JP# ...Bon, prenons un objet du quotidien pour voir comment on le testerait...
> ...ton parapluie tiens ! Au moins il servira.

## media fade-from contain
<img src="src/img/parapluie-ouvert.jpg"/>

> #AC# Super id√©e, j'adore les parapluies, c'est tellement pratique.
> Mais attends, on est dev front, j'ai aucune id√©e des techno de test de parapluie.
> #JP# La premi√®re chose que tu te demandes c'est "Quelles sont les techno ?"
> Perso, je pr√©f√®re me demander... _Comment on teste un parapluie_

## text fade-from
ü§î Comment on teste un parapluie ? 
> #AC# C'est pas b√™te √ßa, on pourrait m√™me se poser la question de ... _Qu'est-ce qu'on teste ?_

## text
Qu'est-ce qu'on teste ?
> #AC# D√©j√†, il nous faut une mati√®re imperm√©able, sinon c'est pas tr√®s utile.

## media fade-from contain
<img src="src/img/toile.png"/>

> #JP# Il nous faut un proc√©d√© qui nous permet de tester unitairement la toile du parapluie.
> #AC# Ah oui je vois o√π tu veux en venir, un genre de test unitaire o√π on s'occupe uniquement de la toile.
> √áa nous permettrait d'√©viter de fabriquer un parapluie qui nous prot√®ge pas du tout de la pluie.

## text white
<strong>Test unitaire</strong> de la toile
> #JP# Clairement ce serait d√©j√† bien, mais toi comme moi, on sait que le principal souci des parapluies...
> #AC# C'est que le m√©canisme est souvent fragile et fini par casser, le rendant inutilisable.
> Il nous faudrait un proc√©d√© pour tester la robustesse du m√©canisme.

## media fade-from contain
<img src="src/img/mechanisme.png"/>

> Il faudrait qu'on puisse ouvrir et fermer le m√©canisme un grand nombre de fois pour s'assurer qu'il ne casse pas.
> #JP# Un peu comme un test d'int√©gration, on v√©rifie qu'un ensemble des pi√®ces fonctionnent bien ensemble.

## text white
<strong>Test d'int√©gration</strong> du m√©canisme
> #JP# Oui compl√®tement, ce serait d√©j√† pas mal, mais on sait tous que le vent est l'ennemi num√©ro 1 des parapluies.
> #AC# Mais comment on fait pour tester √ßa ? On va pas arr√™ter la production tant qu'il n'y a pas de vent.
> #JP# On peut surement faire passer les parapluies en soufflerie, pour s'assurer qu'ils tiennent le coup.
> #AC# Ah oui, la soufflerie, ce serait comme un test avec des mocks.

## text white
On <strong>mock</strong> le vent avec la soufflerie
> #JP# Tout √ßa, √ßa nous donne un parapluie hydrophobe, robuste et r√©sistant au vent.
> Mais √ßa nous assure toujours pas qu'on est √† l'abri de la pluie.
> #AC# En effet, en testant morceaux par morceaux notre parapluie, on n'est pas √† l'abri de ne pas l'√™tre.

## media fade-from logo
<iframe src="https://giphy.com/embed/BmQPKjwhScjdK" frameBorder="0" allowFullScreen></iframe>
> #AC# Pour √ßa, il nous faudrait un test end-to-end, un test qui nous assure que le parapluie remplit bien sa fonction premi√®re.
> On pourrait simuler de la pluie pour v√©rifier que le parapluie nous prot√®ge bien.

## text white
De <strong>bout en bout (e2e)</strong> l'usage du parapluie
> #JP# Ok, maintenant on est encore plus s√ªr que notre parapluie est de qualit√©.
> #AC# On pourrait envoyer des nouveaux mod√®les de parapluie pour voir si on a des retours positifs / n√©gatifs.

## text white
Du <strong>canary testing</strong> sur les nouveaux mod√®les
> _#JP#_ Yes, on appelle en g√©n√©ral √ßa du canary testing, on envoie un petit groupe de personnes pour tester un nouveau produit.

## text
ü§î
> @00:04:30@ ¬±01:00
> #AC# Normalement vous devriez vous demander "Pourquoi ces deux l√† me parlent de parapluie ?"
> On a voulu vous montrer que les tests, c'est pas juste une question de techno, c'est aussi une r√©flexion et une strat√©gie.
> Par cette parabole....douteuse... on vous a partag√© quelques d√©finitions sur des proc√©d√©s de tests qui r√©pondent √† diff√©rents besoin.
> Les d√©finitions de tests unitaires, d'int√©gration et d'end-to-end, de mock varient beaucoup de techno en techno, de personne en personne, de projet en projet.
> On ne cherche pas ici √† donner des d√©finitions universelles, on se met juste d'accord sur ce qu'on entend par ces termes et sur les besoins auxquels ils r√©pondent.
> Clairement, si vous les appelez autrement, il n'y a pas de soucis.
> Maintenant qu'on a fait les zozo avec nos parapluie, quelle strat√©gie de test on peut appliquer √† nos projets, dans la vrai vie. ?

## text
Quelle <strong>strat√©gie</strong> alors pour mes tests ?
> #AC# Quand on vous parle de conception / structuration des tests, vous avez certainement un mod√®le en t√™te.
> Vous avez probablement entendu parl√© de la pyramide des tests.
> C'est le mod√®le le plus connu, mais le connaissez-vous vraiment ?

## text white
La pyramide des tests
> #AC# La pyramide des tests dans votre t√™te c'est quoi ?
> Quand on a fouill√© avec Jules, on a trouv√© √©norm√©ment de repr√©sentation de celle-ci et vous aller voir c'est assez surprenant.
> Aller, soir√©e diapositives, voici donc 3 exemples trouv√©s sur internet.

## ext-content
<img src="src/img/pyramide/pyramide-1.png" />
Pyramide des tests mod√®le 1

> #AC# Bel arc en ciel n'est-ce pas ? 
> On voit une notion de vitesse et peut-√™tre de scope.

## ext-content
<img src="src/img/pyramide/pyramide-2.png" />
Pyramide des tests mod√®le 2

> #AC# Ici on voit des "solutions tests", qui ne sont pas d√©finies dans l'article connexe.
> Pourquoi pas des "Problem tests" ?

## ext-content white
<img src="src/img/pyramide/pyramide-3.png" />
Pyramide des tests mod√®le 3 / ?

> #AC# Celle-l√† je l'aime bien, elle a le bon go√ªt du fait maison.
> Ici E2E pour end-to-end
> #JP# Bon on pourrait jouer des heures √† vous montrer des pyramides, mais on va pas le faire.
> 3 √©tages, parfois 2 √©tages, plusieurs dimensions, clairement le mod√®le est fortement interpret√©.
> Alors sur quoi pouvons-nous nous baser pour le mod√®le de la pyramide des tests ?

## text white
Mais en vrai √ßa vient d'o√π ?
> #AC# Le r√©flexe qu'on devrait avoir ce serait de savoir d'o√π √ßa vient au d√©part.
> Je suis assez d√©rang√© de toutes les interpr√©tations qu'on peut voir.
> J'ai le sentiment que tout le monde r√©interprete un mod√®le sans avoir fait l'effort d'aller chercher la source.
> Ou m√™me sans dire que c'est une variante du mod√®le initiale.
> Et m√™me...

## text white
Mais en vrai √ßa vient <strong>de qui</strong> ?
> #AC# de qui !
> D√©j√†, contrairement √† ce qu'on peut lire dans beaucoup d'article, non ce n'est pas Martin Fowler.

## media contain logo
<img src="src/img/mike-cohn.png">

> #AC# C'est Mike Cohn, dans son livre "Succeeding with Agile: Software Development using Scrum".

## ext-content
<img src="src/img/succeeding-with-agile.png">

> #AC# Dans ce livre il d√©fini un mod√®le en forme de pyramide pour comparer 3 typologies de tests tout en comparant leur facilit√© de mise en oeuvre et leur capacit√© √† apporter du feedback rapidement. 
> Voyons √ßa un peu de plus pr√®s.

## ext-content contain
<img src="src/img/pyramide/pyramide-mike-cohn.png" />
Pyramide des tests de <strong>Mike Cohn</strong>

> D√©j√† dans sa pyramide, dans le chapitre il explique qu'il place que des tests automatis√©s.
> Dans le mod√®le de base il ne compare pas les tests √† la main avec des tests automatis√©s.
> Il place en haut de la pyramide les tests UI, il ne parle pas sp√©cifiquement de test E2E, il parle juste de tests d'interface.
> Ensuite il place les tests de service, et enfin les tests unitaires.
> Il explique que les tests UI sont les plus couteux √† mettre en place, les plus lents, les plus fragiles.
> Rappel, en 2009 jules est en CE1, et clairement pour tester de mani√®re automatis√©e une interface graphique c'est pas la joie.
> On est pas loin de taper deux silex entre eux pour faire du feu.
> J'ai commenc√© a faire des tests automatis√©s en 2014, et m√™me √† cette √©poque l√†, on gal√©rait.
> Si je vous parle de Selenium, il y a peut-√™tre quelques frissons qui vont se propager dans la salle.

## text
Les limites de ce mod√®le
> Ce mod√®le qui connait beaucoup de d√©rives nous parait un peu d√©pass√©.
> Pour plusieures raisons.
> D√©j√† en 2025 il est bien plus facile de setup des tests d'UI.
> Voire m√™me aussi facile que des Test unitaires.
> Que les tests unitaires peuvent √™tre rapide √† setup mais qu'ils souffrent souvent d'overspecifying.

## text
Un mod√®le de <strong>2009</strong>
> #JP# On ne va pas jeter la pierre √† Mike Cohn, lui m√™me reconnait dans son livre que cette pyramide fait sens en le liant au contexte technologique.
> #AC# Pour autant on voit encore ce mod√®le expos√©, transform√©, avec plus ou moins d'√©tages sans pour autant qu'on se pr√©occupe du message initial.

## ext-content contain
<img src="src/img/honeycomb-test-model-033e461521df0d8b1cf5bf7dc22e1380.png">
https://cookbook.marmicode.io/angular/pragmatic-testing-strategy/
Designing a Pragmatic Testing Strategy - <strong>Y Jaaidi</strong>

> #AC# Pour nous, une fa√ßon de mod√©liser qui nous semble pertinente aujourd'hui, c'est le mod√®le exprim√© dans un article de Younes Jaaidi avec un hexagone des tests.
> _Sur cette slide on r√©f√©rence son article, dont le lien est dans le qrcode en bas_
> Ce mod√®le r√®gle deux parties floues de la pyramide des tests qu'on a pu voir.
> #JP# D'abord, il l√®ve l'ambigu√Øt√© entre les tests d'int√©gration et les tests unitaires, en les regroupant sous le terme de tests "narrow".
> Ensuite, il d√©place ces tests unitaires vers le centre de l'hexagone, pour montrer qu'ils sont au c≈ìur de la strat√©gie de test.
> Mais qu'ils ne sont pas la base de tout et qu'ils ne sont pas suffisants.

## text white
üî¨
> @00:14:30@ ¬±03:00
> #JP# Maintenant voyons un peu ce qui se passe dans le monde r√©el, en sortant du mod√®le de Mike Cohn.
> J'ai mont√© un institut de sondage Pipo forg√© par nos biais de confirmation et quelques √©changes que nous avons eus depuis plusieurs ann√©es quand on pose la question.
> Soit en meetup, en conf√©rence, en menant des audits, en faisant des entretiens, en regardant les r√©sultats de sondages et d'enqu√™tes.
> On a souvent pos√© la question: "Et vous, comment vous testez ?"
> Voici donc quelques typologies de r√©ponses observ√©es, on va essayer de sainement les critiquer au sens propre du terme.
> En essayant de montrer les limites de ces approches.

## poster fade-to main
Les believers
==========
_"Nous on ne test pas, on a pas le temps."_
<img src="src/img/chaplin.gif" style="max-height: 300px;" />
==========
xxxxxxxxxx
xxxxxxxxxx
----------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxx
==========
> #AC# Malheureusement la r√©ponse qu'on entend le plus souvent.
> Nous on teste pas, celle-ci, je l'aime particuli√®rement.
> Souvent elle est teint√© de frustration, de manque de temps, de pression, de manque de comp√©tence, de manque de ressource, etc.
> R√©guli√®rement je r√©ponds pour d√©tendre un peu "Mais du coup vous faites que du code qui marche du premier coup ?".
> #JP# Vous allez nous dire, on abuse, il y en a pas tant que √ßa des √©quipes qui ne testent pas.
> Alors pour s'y √™tre int√©ress√©, il y a relativement peu d'√©tude statistique fiable sur le sujet.
> Mais il y en a une d√©j√† qu'on pourrait citer.
> Vous connaissez le State of JS ? 

## ext-content contain
<img src="src/img/state-of-js.jpg" screenshot-url="https://stateofjs.com/en-US"/>
https://stateofjs.com/en-US
State of JS 2024

> C'est une √©tude qui est men√©e chaque ann√©e sur l'√©cosyst√®me JS.
> Il y a un chapitre qui s'int√©resse aux outils de tests voici donc quelques r√©sultats.

## barchart unit="%" max="50"
State of JS 2024
O outil : 21 red
1 outil : 9
2 outils : 10
3 outils : 10
4 outils : 10
5+ outils : 40

> Ca, c'est ce que d√©clarent les r√©pondants √† l'√©tude.
> D√©ja on peut se rassurer, les √©quipes qui ne testent pas sont minoritaires.
> On a cependant presque un quart qui n'utilise aucun outil de test.

## poster main
Les believers
==========
_"Nous on ne test pas, on a pas le temps."_
<img src="src/img/chaplin.gif" style="max-height: 300px;" />
==========
xxxxxxxxxx
xxxxxxxxxx
----------
21% n'automatisent pas leurs tests
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxx
==========
> Ne pas automatiser ses tests c'est souvent privil√©gier du temps humain de v√©rification.
> Il n'y a pas de magie, les √©quipes de devs vont manuellement tester lors de leur d√©veloppement, les √©quipes produits, les √©quipes de tests parfois.
> #JP# C'est souvent une question de priorit√©, de culture, de comp√©tence, de ressource, de maturit√©, etc.
> Ces approches sans automatisations peuvent paraitre de prime abord plus rapide, mais elles sont souvent plus couteuses √† long terme.
> La confiance sur le code va reposer sur la m√©moire humaine, la documentation, la communication.
> #AC# Clairement la strat√©gie du **rien** ne nous parait pas viable mis √† part dans un mode draft ou on sait qu'on va jeter explicitement ce qu'on produit.
> On entend parfois des √©quipes qui font reposer le test manuels sur des √©quipe QA qui ont toute la charge de la qualit√©.
> C'est le mod√®le qu'on appelle parfois le "Ice Cream Cone" pos√© par **Alister B Scott**.

## ext-content contain
<img src="src/img/pyramide/ice-cream.png"/>
https://alisterscott.github.io/TestingPyramids.html
Ice cream modele - <strong>Alister B Scott</strong>

> #AC# C'est souvent une strat√©gie de test tr√®s co√ªteuse, qui va ralentir le d√©veloppement, qui va √™tre source de frustration.
> On ne dit pas que d'avoir des tests manuels c'est mal hein, on va juste dire que centraliser sa strat√©gie de tests dessus n'est pas pour nous une bonne id√©e.
> √áa ne passera pas √† l'√©chelle.
> Il y a un vrai biais de perception du temps quand on d√©v√©loppe sans automatiser ses tests.

## ext-content contain
<img src="src/img/testing-biais.png"/>
https://cookbook.marmicode.io/angular/pragmatic-testing-strategy#development-time-perception-bias
Development Time Perception Bias - <strong>Y Jaaidi</strong>

> #AC# Ici on voit bien qu'en impl√©mentant pas de tests automatis√©s, on a une perception du temps de d√©veloppement qui est fauss√©e.
> Sans m√™me parler TDD, on est perp√©tuellement couper par une phase de v√©rification manuelle qu'on doit r√©p√©ter √† chaque it√©ration.

## poster main
Les technophiles
==========
_"On fait du Jest / Testing Library / Cypress / ..."_
xxxxxxxxxx
xxxxxxxxxx
----------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxx
==========
<img src="src/img/scott-blake-wq7oyx_Kx-4-unsplash.jpg" style="min-height: 400px" />
==========
> @00:20:00@ (06:40)
> #JP# En deuxi√®me position des r√©ponses √† la question "Comment vous testez ?" on a souvent des r√©ponses plus techniques.
> On nous r√©pond des technos de tests, des outils, des librairies, des frameworks.
> Comme si ces outils √©taient une fin en soi. 
> Soyons clair des outils de tests c'est bien, mais savoir clairement "Qu'est-ce qu'on teste ?" est mieux.

## poster main
Les technophiles
==========
_"On fait du Jest / Testing Library / Cypress / ..."_
xxxxxxxxxx
xxxxxxxxxx
----------
Faire des tests, juste pour en faire
xxxxxxxxxx
xxxxxxxx
==========
<img src="src/img/scott-blake-wq7oyx_Kx-4-unsplash.jpg" style="min-height: 400px" />
==========
> #JP# On a r√©guli√®rement cette r√©ponse quand la strat√©gie de test semble impos√©e de mani√®re tr√®s solutionniste.
> On fait des tests parce qu'on nous a dit d'en faire / qu'on nous a dit que c'√©tait bien.
> Est-ce que ces outils, ces librairies vous aident ou au contraire vous infliges de l'aide.
> Clairement vous ici dans la salle, si vous regardez vos tests, √† quoi vous sont ils utiles ?
> Qu'est-ce qu'ils vous apportent au jour le jour ?
> On observe alors de ces √©quipes des tests tr√®s li√©s au code source, ou bien des tests de tr√®s mauvaise qualit√©.
> Quelques exemples:

## code
```gherkin

Feature: 404 page
  
  Scenario: 404 page
    When I access access to an non existing page
    Then I should not see the homepage
    And I should not see the homepage image
    And I should not see my article description
```
> Vous avez surement rencontr√© des tests qui testent rien ? des tests qui font des non observations par exemple.
> Ici avec un test √©crit en Gherkin, qui ne v√©rifie rien, j'√©tais content de voir qu'il marchait encore quand j'ai supprim√© le code de la page 404.
> Inspir√© de fait r√©√©ls...

## code
```js
it('should do addition', () => {
  expect(addition(1, 1)).toBe(2)
})

it('should do addition', () => {
  expect(substract(1, 1)).toBe(0)
})
```
> Des tests mal nomm√©s, "Aller hop je copie ce test et je modifie juste le code et on est bon."

## code
```js
it('should render', () => {
  const { container } = render(<MyComponent />)
  expect(container).toMatchSnapshot()
})
```
> Et mes pr√©f√©r√©s, les tests qui testent la librairie de test, super! 
> Le composant il pourrait afficher une page vide, un site web ou autre on sait m√™me pas.
> Qu'est-ce qu'on regarde l√† ?

## blank white
> @00:22:30@ ¬±01:00

## poster main
Les Sceptiques
==========
_"Nous on teste absolument tout, coverage √† 100%"_
xxxxxxxxxx
<img src="src/img/bianca-ackermann-fUIDHNjwbto-unsplash.jpg" />
==========
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxx
------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxx
==========
> #AC# En troisi√®me position, on va retrouver des √©quipes qui ont une strat√©gie de test tr√®s quantitative.
> Pas forc√©ment associ√© √† des pratiques TDD, BDD, on retrouve cependant de plus en plus d'√©quipe qui utilisent des indicateurs de coverage de test pour objectiver leur strat√©gie de tests.
> On a souvent des √©quipes qui vont se fixer des objectifs de coverage de test, 80%, 90%, 100%.
> Le coverage c'est comptabiliser le ratio de lignes de code qui sont ex√©cut√©es par vos tests.
> √áa ne vous dit pas du tout si vos tests sont bons, si ils sont pertinents, si ils sont efficaces.
> Est-ce que cependant le coverage est une bonne m√©trique ?
> Est-ce que chacune des lignes de votre codebase m√©rite d'√™tre test√©e avec la m√™me pr√©cision, la m√™me rigeure, le m√™me d√©tail ?

## poster main
Les Sceptiques
==========
_"Nous on teste absolument tout, coverage √† 100%"_
xxxxxxxxxx
<img src="src/img/bianca-ackermann-fUIDHNjwbto-unsplash.jpg" />
==========
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
------
Le coverage n'est pas un indicateur de qualit√© de tests
xxxxxxxxxx
xxxxxxx
==========
> #AC# Le coverage n'est qu'un indicateur de quantit√© et de ratio, il ne donne aucune indication sur la qualit√© des tests.
> Il est tr√®s facile de faire des tests qui couvrent 100% d'une fonction / class / module mais qui ne font aucun expect par exemple.
> Une strat√©gie quantitative va √©galement vous apporter des probl√®mes de scalabilit√© de vos tests.
> On se retrouve avec √©norm√©ment de tests √† faire tourner ce qui va ralentir votre CI, ralentir votre d√©veloppement, le d√©lai pour avoir du feedback en sera que plus long.

## text
<i>"Je push, je te dis dans 40min si c'est bon"</i>
> #AC# Avoir beaucoup de tests √ßa peut devenir un enfer, attendre 40min pour avoir du feedback √ßa peut √™tre tr√®s compliqu√©.

## poster main
Les Sceptiques
==========
_"Nous on teste absolument tout, coverage √† 100%"_
xxxxxxxxxx
<img src="src/img/bianca-ackermann-fUIDHNjwbto-unsplash.jpg" />
==========
xxxxxxxxxx
La CI qui met 2 heures.
------
Le coverage n'est pas un indicateur de qualit√© de tests
xxxxxxxxxx
xxxxxxx
==========
> #AC# Est-ce que run **tous** les tests **tout le temps** est une bonne id√©e ?
> On verra ensemble des techniques pour √©viter √ßa.
> Est-ce que toutes les features que vous testez m√©ritent d'√™tre test√©es avec la m√™me rigueur ?

## poster main
Les good enough
==========
_"On teste que cette partie l√†, le reste c'est pas important"_
<img src="src/img/david-goodenough.png" style="object-position: top; min-height: 300px">
==========
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxx
==========
> @00:25:30@ ¬±01:00
> #JP# Enfin, et c'est beaucoup plus rare, on a des √©quipes qui vont avoir une strat√©gie de test avec du focus.
> Ou avec une quantit√© de tests tr√®s limit√©e.
> Est-ce critiquable ? Est-ce que c'est une bonne id√©e ?
> Clairement, on a souvent des √©quipes qui vont se concentrer sur des parties de leur codebase, souvent les plus critiques.
> On pourrait se dire que c'est une mauvaise id√©e, mais en fait c'est une strat√©gie qui peut √™tre tr√®s pertinente.

## poster main
Les good enough
==========
_"On teste que cette partie l√†, le reste c'est pas important"_
<img src="src/img/david-goodenough.png" style="object-position: top; min-height: 300px">
==========
xxxxxxxxxx
xxxxxxxxxx
Une approche pragmatique
xxxxxxxxxx
------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxx
==========

> #JP# Cette vision pragmatique, si elle repose bien sur une analyse de risque, peut √™tre tr√®s pertinente.
> Si clairement on a peu de tests parce qu'on a la flemme o√π qu'on a pas le temps, c'est pas une bonne id√©e.
> Mais si on peut fragmenter son application, identifier les parties les plus critiques, les plus risqu√©es, et les tester en priorit√©.
> _Choisir c'est aussi renoncer_, si on choisi de ne pas tester certaines parties, c'est qu'on a fait le choix de ne pas les tester.
> C'est int√©ressant de creuser le pourquoi.

## ext-content 
<img src="src/img/is_it_worth_the_time_2x.png"/>
https://xkcd.com/1205/
<strong>XKCD 1205</strong>

> #JP# Automatiser des tests √ßa aura un certain cout, un certain temps, une certaine complexit√©.
> Vous connaissez peut-√™tre ce XKCD ?
> C'est une bande dessin√©e qui illustre bien cette probl√©matique.
> Passer des heures √† automatiser des tests sur une feature qui n'est pas importante pour vous, le business de votre entreprise, la codebase enti√®re.
> Est-ce toujours pertinent ?

## ext-content contain
<img src="src/img/gain_perte.jpg" />
Automate Within the sprint - <strong>Mike Cohn</strong>

> #JP# Ces questions de co√ªt et de gain sur l'automatisation on se les pose depuis longtemps.
> Avec le temps, le cout de maintenance, de run d'un test automatis√© risque de d√©passer son gain.
> Mike Cohn dans son livre exposait d√©j√† son point de vue avec ce graphique.
> Pausons nous quelques secondes pour r√©fl√©chir √† ce qu'on a vu.

## text
Quoi en penser ?
<br/>
<br/>
ü§î
> @00:27:45@ ¬±00:30
> #AC# Bon, d'apr√®s ce sondage DIY il nous laisse l'impression que les dev ont pas tous en t√™te toutes les raisons et les b√©n√©fices qu'on tire du fait de tester.

## media contain white
<img onclick="this.src+=''" src="src/img/unzoom.gif"/>

> #AC# En fait, si on d√©zoome et qu'on se demande **pourquoi** on teste, on compte 5 raisons de pourquoi on devrait automatiser des tests.

## kiosk
> #JP# On va vous faire participer un peu ! On va voir si on peut retrouver ensemble ces 5 motivations.
> Selon vous, quelles sont les raisons qui nous poussent √† automatiser nos tests ?
> A vous de jouer !

> Rouge : Conformit√©
> On veut s'assurer que notre application respecte les sp√©cifications et les contraintes, etc. 
> Bleu : Documenter
> Les tests sont une forme de documentation.
> Magenta : Reproductibilit√©
> Les tests permettent de reproduire des comportements. 
> Par exemple un disaster case, on a besoin de pouvoir tester
> mon code dans des conditions non triviales. _Echec de paiement_
> Jaune : Int√©grit√©
> Ils permettent d'assurer un √©tat stable de l'application, dans l'historique du code.
> $Observabilit√©$ de l'√©tat de l'application. Feedback rapide de l'√©tat de l'application.
> Vert : Stabilit√©
> **Non-regression**
> Est-ce que le diff que j'apporte r√©pond bien √† tous les tests d√©j√† en place ? Est-ce que je casse pas quelque chose ? 

## poster main
Nos conseils
xxxxxxxxxx
xxxx
==========
Trucs et astuces
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxx
----------
xxxxxxxxxx
xxxx
==========
<img src="src/img/patrick-notes.png" style="min-height: 18em"/>
==========
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxx
----------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
==========
> @00:32:00@ ¬±01:00
> #JP# Pour r√©pondre aux groupes identifi√©s dans le sondage, on a plusieurs conseils √† vous donner.
> On rappelle qu'il n'y a pas de solution miracle pour vos cas, juste des conseils.
> Il faut aussi garder en t√™te qu'on est des dev front javascript, donc on va vous apporter des conseils qui sont orient√©s vers ce qu'on connait.

<!--
# pr√©senter nos recos: vitest / playwright
## believer (√ßa prend trop de temps)
C'est plus aussi vrai qu'avant
pour les tests unitaires -> vitest **REF** de l'article de Younes
pour les tests UI -> playwright -> **DEMO** d'un test facile
en plus c'est rapide -> **DEMO** playwright overhead
-->
## text
Pour les <strong>believers</strong> ü´µ

> #AC# Pour les believers, qui par _manque de temps_ ne testent pas.
> En 2025 on a deux outils qui peuvent vous aider √† tester plus rapidement.
> La mise en place d'une stack de tests n'est plus si compliqu√© ou long.

## text
Pour les tests <strong>unitaires</strong>...

> Pour les tests unitaires...

## text
Pour les tests <strong><em>narrow</em></strong>...

> qu'on pr√©f√®rerait appeler des tests <strong>narrow</strong> ou √©troits, on vous conseille de regarder du c√¥t√© de Vitest.

## ext-content contain
<img src="src/img/vitest.jpg">
Vitest
https://vitest.dev/

> #AC# On pense notamment √† des outils comme Vitest, qui permettent de lancer des tests unitaires tr√®s rapidement.
> Pour ceux qui ont d√©j√† entendu parler de Jest, il s'agit d'un outil qui se veut √™tre son successeur.
> Il est rapide, simple, bien document√©. 
> Compatible avec les √©cosyst√®me JS r√©cents contrairement √† Jest.
> Il en devient donc un peu son successeur.

## ext-content contain
Vitest: testing DX reimagined, <strong>Vladimir</strong>, ViteConf 2022
https://www.youtube.com/watch?v=oB553Noerlc
<img src="src/img/vitest-presentation.png">

> #AC# Je vous recommande cette conf√©rence de Vladimir, qui explique tr√®s bien Vitest.

## tip
<strong>Pr√©f√®rez Vitest</strong> √† Jest en 2025

> #AC# Pr√©f√©rez donc Vitest √† Jest en 2025, vous ne serez pas d√©√ßu.

## text
Pour vos tests <strong>UI</strong>...
> #AC# Pour vos tests d'UI il existe plusieurs outils maintenant sur le march√© pour piloter des navigateurs.
> Vous connaissez peut-√™tre WebdriverIo, Puppeteer, Cypress, Selenium, etc.
> Celui qu'on a d√©cid√© de vous recommander en 2025 c'est...

## tip
Adopter <strong>Playwright</strong> en 2025
> @00:33:30@ 

> #JP# Playwright
> Il a pas mal de fonctionnalit√©s, qui peuvent couvrir la plupart de vos cas d'usages.
> Mais surtout, il est tr√®s simple √† mettre en place.
> La aussi, en 2 temps 3 mouvements, vous avez un test d'UI qui tourne sur votre ordinateur mais √©galement dans une CI.

## demo

> #JP# Si je prends un exemple, voil√† un site de d√©mo, qui a un bouton qui au clic affiche un r√©sultat.
> J'ai un dossier dans le quel j'ai simplement fait initialis√© playwright avec `pnpm create playwright`.
> Allons voir le test dans `simple.spec.js`.
> On a un test qui va sur la page, cherche un √©l√©ment avec un role titre et v√©rifie le contenu.
> On voit qu'il n'est pas bon, on peut facilement le corriger en arrageant le titre.
> L√† c'est peut-√™tre un peu l√©ger, on pourrait d√©cider de rajouter un test qui clic sur notre bouton.
> Cr√©eons un nouveau fichier `button.spec.js` qui: va sur la page, clic sur le bouton et v√©rifie le contenu.

## text
‚è± 650ms
> #JP# Mon test ne fait que cliquer sur un bouton... c'est un peu long non ?
> Il faut imaginer que devant un test unitaire, c'est √† peu pr√®s 10 fois plus...
> Bon, bah c'est pas g√©nial comme nouvelle, peut √™tre qu'on peut se demander... _qu'est ce qui est long ?_

## text
Qu est-ce qui est long ? üê¢
> #JP#... peut √™tre que vous avez des id√©es... mais j'aime bien exp√©rimenter pour √™tre sur.
> Alors j'ai fait en sorte que le delai de l'API que j'appelle soit param√©trable.
> Comme √ßa je peux mesurer la diff√©rence entre la r√©ponse de l'API et le temps total du test.
> Ca me donne une id√©e de l'overhead de mon test.

## stackedchart unit="ms" 
Temps des tests
664ms : 200,#4285f4;464,#34a853;
> #JP# En param√©trant l'API √† 200ms, on voit que le test prend 295ms.


## stackedchart unit="ms" 
Temps des tests
503ms : 400,#4285f4;103,#34a853;
913ms : 800,#4285f4;133,#34a853;
1716ms : 1600,#4285f4;116,#34a853;

## text
Comment y rem√©dier ?

## tip
<strong>Mockez</strong> les APIs de vos tests UI

## ext-content contain
<img src="src/img/playwright.png">
https://playwright.dev/docs/mock
Playwright - <strong>Mocking</strong>

> Montre API mock Playright


## blank white
> @00:38:30@ ¬±01:00
> Bon... maintenant quels conseils pour les technophiles !

## text
Pour les <strong>technophiles</strong> ü´µ

> #AC# Essayez une approche plus √† proximit√© du m√©tiers de vos applications / outils.
> Pensez d'abord √† vos it de tests plutot qu'√† comment les impl√©menter.
> Vous avez des tests en place, c'est super cool mais essayons d'en am√©liorer la qualit√© et d'√©loigner un peu leur impl√©mentation du code source
> C'est souvent l'aspect de documentation pr√©senter plus haut qui peut vous manquer.

## tip
Essayer le <strong>BDD</strong> ou l'<strong>ATDD</strong>

> Essayer de d√©crire par vos tests, le comportement de votre application, behavior driven development, ou acceptance test driven development.
> Des outils comme Gherkin, Cucumber, Specflow, etc. peuvent vous aider √† √©crire des tests plus lisibles, plus compr√©hensibles, plus maintenables.

## code
```gherkin
Feature: Blog Homepage
  
  Scenario: Should display 3 articles
    Given the user is on the blog homepage
    Then the user should see 3 articles
    When the user clicks on the first article
    Then the user should be redirected to the article page
```
> Dans cet exemple-ci on voit qu'on d√©crit juste le m√©tier et chaque ligne appel√©e Step Definition va √™tre impl√©ment√©e dans un test.
> En gros, c'est un fichier test avec un language naturel qui pilote le test.
> Cela force √† d√©crire le m√©tier.
> L'ensemble de vos fichier Gherkin vont devenir une documentation vivante de votre application.

## ext-content contain
<img src="src/img/cucumber.png">
https://cucumber.io/
Cucumber

> Jeter donc un oeil √† Cucumber, qui remplira tr√®s bien cette fonction pour vous.
> Bon pour les technophiles, on a un autre conseil pour vous.

## tip
Soignez votre <strong><em>testbase</em></strong> comme votre codebase

> Et oui, clairement les techno c'est bien, bien s'en servir c'est mieux.

## ext-content
<img src="src/img/how-you-do-one-thing.webp">
<h3 style="width:100%">"How you do anything is how you do everything" - Le m√©chant dans <strong>John Wick 4</strong></h3>

> #AC# Si vous aimez vos outils et votre code, alors donner autant d'amour √† votre testbase.
> Tout d'abord par souci de coh√©rence, mais surtout parce que quand on y r√©fl√©chit un peu, on devrait avoir des contraintes, des r√®gles similaires.
> √Ä savoir, le code des tests doit √™tre lu, compris, maintenu dans le temps.
> #AC# Si on ne se fixe pas de r√®gle, on peut vite se retrouver avec des tests qui se ressemblent, qui se dupliquent.
> Sachez que dans Eslint, l'outil de lint en JS le plus connu, il en existe des tas.

## ext-content contain
<img src="src/img/expect-expect-light.png">
Le readme dans le repo <strong>eslint-plugin-vitest</strong>

> #AC# Ma pr√©f√©r√©e √©tant la r√®gle `expect-expect` de eslint-plugin-vitest.
> Qui v√©rifie que pour chaque test, on v√©rifie bien au moins quelque chose.
> Il existe pleins de set de r√®gles de lint pour vos fichiers de tests qui vont vous aider √† en maintenir la qualit√©.
> Appliquer du lint sur vos tests si ce n'est pas d√©j√† le cas.
> #AC#: Je me rappelle avoir appliquer Gherkin-lint sur une base d'un projet, √ßa a √©t√© sport mais b√©n√©fique.
> J'ai pu faire le m√©nage de plein de tests qui testaient rien ou √©taient mal √©crits.

## blank white
> #JP# Bon et pour les sceptiques...

## text
Pour les <strong>sceptiques</strong> ü´µ
> @00:40:30@ ¬±00:30
> #JP# Pour les sceptiques, qui testent tout, avec un $objectif de coverage$.
> Comment vous dire.... le coverage n'est pas un indicateur pertinent de la qualit√© de vos tests.
> C'est un indicateur quantitatif mais il peut vous donner une fausse indication de la qualit√© de vos tests.

## tip
N'objectivez pas le <strong>coverage</strong>

> #JP# "N'objectivez pas le coverage".
> Une mesure quantitative ne peut pas se soustraire d'une mesure qualitative si on veut garder du sens.
> Un principe int√©ressant pour compl√©ter l'analyse de coverage, c'est le mutation testing.
> L'id√©e en deux phrases, c'est de modifier le code source et de voir si les tests vos tests d√©tectent en √©chouant.

## ext-content contain
<img src="src/img/strykerJS.png">
https://stryker-mutator.io/
Optez pour du <strong>mutation testing</strong>

> #JP# Si les tests passent m√™me avec des modifications dans votre code, alors ce sont des tests ne testent pas grand chose.
> Le sujet en lui est tr√®s vaste et on aurait pu passer la conf√©rence enti√®re dessus. 
> On vous invite √† regarder des outils comme Stryker, PIT, etc.

## ext-content
<img src="src/img/mutationtesting.jpg"/>
https://www.youtube.com/watch?v=297tyPsXOm8
Mutation Testing - <strong>Lo√Øc Knuchel</strong>

> #JP# Voil√† une conf√©rence que je recommande sur le mutation testing si vous voulez creuser c'est un sujet tr√®s int√©ressant.
> Qui pose √©galement quelques questions sur la performance de vos tests et le ciblage.

## tip
<strong>Ciblez</strong> vos tests
> #JP# Est-il pertinent de lancer tous vos tests √† tous les coups ? 
> Si votre CI met 40min a vous donner un feedback positif ou negatif, clairement c'est dommage.
> _le test le plus rapide, c'est celui qu'on ne lance pas_.
> Si votre architecture le permet, configurez votre projet pour qu'il ne run que les tests impact√©s par vos changements.
> Les outils de tests, en tout cas c√¥t√© javascript, comme Jest et Vitest proposent des outils pour run les tests sur votre diff git.
> Vous allez me dire "Oui mais justement je voudrais lancer tous mes tests pour voir les impacts transverses".
> Dans les fait, il est assez rare de casser une application en transersal quand on touche √† une ligne de code (mais √ßa peut arriver).

## ext-content contain white
<img src="src/img/changed.png"/>
Le flag <strong>--changed</strong> de Vitest

> #JP# Chez vitest, on a le flag `--changed` auquel on peut passer un hash de commit pour run les tests sur les fichiers qui diff√®rent depuis le HEAD.
> Utiliser ce flag dans vos CI quand vous ne modifier que des sources ou des tests.
> Et lancer tous vos tests pour certaines op√©rations comme des mont√©es de version de d√©pendances ou sur la branch principale.

## ext-content contain white
<img src="src/img/nxaffected.png">
Nx affected project graph when <strong>lib10</strong> is changed - Nx docs

> #JP# Dans un contexte _monorepo_, les outils de gestions permettent de run les tests sur les modules impact√©s par vos changements. 
> Ici, on a `nx affected`....
> Si on fait une modif dans le module "lib10", on va run les tests de "lib10" et des modules qui d√©pendent de "lib10", mais pas les autres.
> Cette option vous la retrouverez dans la plupart de ces outils.
> dans la plupart des cas vous n'avez pas besoin de run tous les tests dans votre CI.

## text
<strong>--bail</strong>
> #JP# Ce que vous voulez, c'est √™tre pr√©venu au premier tests qui casse pour rapidement intervenir.
> C'est ce que fait l'option --bail que vous retrouverez dans la plupart des outils de tests.

## blank white
> Ok et pour les good enough ?

## text
Pour les <strong>good enough</strong> ü´µ
> @00:42:30@ ¬±00:30
> #AC# Pour les good enough, qui testent que certaines parties de leur codebase, qui ont une strat√©gie de test tr√®s cibl√©e.
> Vous avez une strat√©gie de test, ok c'est cool ! 
> Mais est-ce qu'il est facile pour une nouvelle personne √† onboarder de comprendre votre strat√©gie de test ?
> Etes-vous sur que votre strat√©gie r√©pond bien aux 5 raisons √©voqu√©es plus t√¥t ?
> #AC# pour les "good enough" et m√™me tous les autres, on vous conseille de documenter votre strat√©gie de test.

## tip 
<strong>Documentez</strong> votre strat√©gie de test
> #AC# Ok vous me direz c'est cool mais comment ?
> On vous propose un nouveau Standard.
> #JP# Vous connaissez peut-√™tre les standard dans l'open source

## text
<strong>README</strong>.md
> #AC# Comme Readme.md pour d√©crire l'essentiel de votre projet

## text
<strong>CONTRIBUTING</strong>.md
> #AC# Comme CONTRIBUTING.md pour d√©crire comment installer votre projet from scratch et proposer une contribution
> On vous propose donc de rajouter un

## tip
Ajouter un <strong>TESTING</strong>.md
> #AC# TESTING.md

## demo
```txt
# Testing.md
```
> D√©finir dans un document des explications sur votre strat√©gie de test.
> Versionn√© avec votre code, √©volutif et surtout li√© √† votre projet sp√©cifiquement.

## text
Bon, au final...
> @00:43:50@ ¬±00:30
> Au final, on a vu qu'il n'y a pas de solution miracle pour vos tests ni votre strat√©gie de tests.
> Tout va d√©pendre du context que vous avez, de votre √©quipe, de votre projet, de votre entreprise.
> L'automatisation est un vrai plus pour vous aider √† it√©rer mieux et plus vite.
> Mais la mise en place d√©pendra de votre strat√©gie, de vos choix.
> Si une personne porte un Kway sous son parapluie, elle n'est pas forc√©ment folle, elle a peut-√™tre juste une bonne raison.
> #JP# On vous invite √† r√©fl√©chir √† vos tests, √† votre strat√©gie de tests, √† vos outils, √† vos librairies.
> Ne prenez pas les mod√®les de tests pour des v√©rit√©s absolues, adaptez les √† votre contexte.
> Gardez juste en tete les 5 raisons pour lesquelles on souhaite automatiser les tests, et vous devriez vous en sortir.

## poster main
Merci beaucoup !
==========
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxx
==========
xxxxxxxxxx
xxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxx
==========
> @00:45:00@

## credits

R√©f√©rences :

* D√©p√¥t de la pr√©sentation : https://github.com/jpoissonnet/talk-test/

Liens :
* state of js : https://stateofjs.com/en-US
* Alister B Scott, Ice Cream model : https://alisterscott.github.io/TestingPyramids.html

* Designing a Pragmatic Testing Strategy : https://cookbook.marmicode.io/angular/pragmatic-testing-strategy/
* Why Vitest? : https://cookbook.marmicode.io/angular/why-vitest/
Images :

* photos des parapluies : https://www.neyrat.fr/
* pyramide des tests 1 : https://thumbs.dreamstime.com/b/pyramide-de-test-avec-interface-utilisateur-tests-d-int%C3%A9gration-et-unitaires-essai-vecteur-unitaire-282317017.jpg
* pyramide des tests 2 : https://blog.atinternet.com/wp-content/uploads/2020/06/ROI-test.jpg
* pyramide des tests 3 : https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IA6N133_wkTin6DMq30u0w.png
* mike cohn : https://upload.wikimedia.org/wikipedia/commons/a/ac/WEB_RES-Mike_Cohn-%C2%A9-2016-Hows_Your_Headshot-6.jpg
* image de chantier : https://unsplash.com/fr/photos/homme-en-veste-grise-et-orange-tenant-un-appareil-photo-reflex-numerique-vert-et-noir-pendant-la-journee-wq7oyx_Kx-4
* m√©chant de john wick : https://villains.fandom.com/wiki/Marquis_de_Gramont?file=F6iIyvDbMAAqS8A.jpg
* Nx affected graph : https://nx.dev/ci/features/affected#run-only-tasks-affected-by-a-pr

Polices :

* Yanone Kaffeesatz : https://fonts.google.com/specimen/Yanone+Kaffeesatz
* Just Another Hand : https://fonts.google.com/specimen/Just+Another+Hand
* Boogaloo : https://fonts.google.com/specimen/Boogaloo
* Interstate : https://fonts.adobe.com/fonts/interstate
* Sufler : https://www.dafontfree.io/sufler-font/
* OperatorMono : https://www.typography.com/blog/introducing-operator

Remerciements :

* Hubert Sablonni√®re : pour lui m√™me et ses outils hyper pratiques pour les slides
* Jules : pour sa patience et sa pers√©v√©rance malgr√© ses cours en parall√®le
* Antoine : pour sa bienveillance √† toute √©preuve
