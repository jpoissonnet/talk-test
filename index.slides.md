---
author:
author-twitter:
author-company:
event: Snowcamp
city: Grenoble
date: 23 janvier 2025
---

# Tester c'est tricher

## blank black
> @00:00:00@
> #JP# Dis voir Antoine, tu devrais peut-√™tre leur expliquer pourquoi tu te trimbale avec un parapluie alors qu'il ne pleut pas ici.
> $AC$ tu sais, on est jamais trop prudent, imagine il pleut et bien tu ferais pas le malin.
> #JP# T'as pens√© √† porter un Kway dessous histoire d'√™tre sur ?
> $AC$ Malin j'y avais pas trop pens√©...
> Bon aller, on est pas la pour √ßa.

## poster fade-from main
Tester c'est tricher
==========
Antoine Caron _Engineering Manager @Scaleway_ !
xxxxxxxxxx
xxxxxxxxxx
xxxx
xxxxxxxxxx
xxxxxxxx
==========
xxxxxxxxxx
xxxxxx
------
Jules Poissonnet _Frontend Dev @Bedrock&nbsp;Streaming_
xxxxxxxxxx
xxxxxxxxxx
==========
xxxxxxxxxx
<img src="src/img/grenoble.png"/>
xxxxxxxxxx
xxxxxxxxx
==========
> $AC$ Bonjour √† toutes et tous, j'esp√®re que vous allez bien et que cette journ√©e se d√©roule comme vous l'esp√©riez.
> Je m'appelle Antoine Caron et je suis Engineering manager Frontend chez Scaleway, vous m'avez peut-√™tre vu l'ann√©e pass√©e vous parler de Gzip.
> #JP# Et moi c'est Jules Poissonnet, Frontend Dev chez Bedrock Streaming.
> Si l'autre malin avec son parapluie et moi-m√™me sommes ici aujourd'hui, c'est pour vous parler de tests.
> C'est un sujet qui nous int√©resse beaucoup et qu'on trouve souvent mal abord√©.
> $AC$ On esp√®re avec cette pr√©sentation ouvrir un peu vos chakras sur la notion de testing.
> Souvent abord√© de mani√®re dogmatique, on va essayer une approche plus pragmatique
> #JP# Que vous fassiez du frontend, du backend, du mobile ou de l'embarqu√©, des "tests" ou pas, on souhaite vous proposer quelques r√©fl√©xions / conseils et approches qui pourraient √™tre utiles et concr√®tes.
> $AC$ Alors pourquoi "Tester c'est tricher", tricher c'est enfreindre des r√®gles √©tablis, des conventions, des normes.
> Pour nous il existe des normes, des strat√©gies de tests qui sont souvent mal comprises, mal appliqu√©es, mal interpr√©t√©es.
> #JP# On va essayer de vous montrer que les tests c'est pas juste une question de techno, c'est aussi une question de r√©flexion, de culture, de priorit√©.

## blank white 
> $AC$ ...Bon, plongeons nous dans un univers qui n'est pas le d√©velopment pour voir ce qu'on peut en tirer
> Il nous faudrait un objet, par exemple.
> #JP# Un parapluie tient, au moins il sera utile.

## media fade-from contain
<img src="src/img/parapluie-ouvert.jpg"/>

> $AC$ Super id√©e, j'adore les parapluies, c'est tellement pratique.
> Mais attends, on est dev front, j'ai aucune id√©e des techno de test de parapluie.
> #JP# La premi√®re chose que tu te demande c'est "Quelles sont les techno ?"
> Perso, je pr√©f√®re me demander...

## text fade-from
ü§î Comment on teste un parapluie ? 
> $AC$ C'est pas b√™te √ßa, on pourrait m√™me se poser la question de ...
> #JP# Et m√™me aller plus loin

## text
Qu'est-ce qu'on teste ?
> $AC$ D√©j√†, il nous faut une mati√®re imperm√©able, sinon c'est pas tr√®s utile.

## media fade-from contain
<img src="src/img/toile.png"/>

> #JP# D√©j√† il nous faut donc un proc√©d√© qui nous permet de tester unitairement la toile du parapluie.
> $AC$ Ah oui je vois o√π tu veux en venir, un genre de test unitaire o√π on s'occupe uniquement de la toile.
> √áa nous permettrait d'√©viter de fabriquer un parapluie qui nous prot√®ge pas du tout de la pluie.

## text white
<strong>Test unitaire</strong> de la toile
> $AC$ Clairement ce serait d√©j√† bien, mais toi comme moi, on sait que le principale souci des parapluies...
> #JP# C'est que le m√©canisme est souvent fragile et fini par casser, le rendant inutilisable.
> Il nous faudrait un proc√©d√© pour tester la robustesse du m√©canisme.

## media fade-from contain
<img src="src/img/mechanisme.png"/>

> Il nous faudrait ouvrir et fermer le m√©canisme un grand nombre de fois pour s'assurer qu'il ne casse pas.
> $AC$ Un peu comme un test d'int√©gration, on v√©rifie qu'un ensemble des pi√®ces fonctionnent bien ensemble.

## text white
<strong>Test d'int√©gration</strong> du m√©canisme
> #JP# Oui completement, ce serait d√©j√† pas mal, mais on sait tous que le vent est l'ennemi num√©ro 1 des parapluies.
> $AC$ Mais comment on fait pour tester √ßa ? On va pas arreter la production tant qu'il n'y a pas de vent.
> #JP# On peut surement faire passer les parapluies en soufflerie, pour s'assurer qu'il tiennent le coup.
> $AC$ Ah oui, la soufflerie, ce serait comme un test avec des mocks.

## text white
On <strong>mock</strong> le vent avec la soufflerie
> #JP# Tout √ßa, √ßa nous donne un parapluie hydrophobe, robuste et r√©sistant au vent.
> Mais √ßa nous assure toujours pas qu'on soit √† l'abris de la pluie.
> $AC$ En effet, en testant morceaux par morceaux notre parapluie, on n'est pas √† l'abris de ne pas l'√™tre.

## media fade-from logo
<iframe src="https://giphy.com/embed/BmQPKjwhScjdK" frameBorder="0" allowFullScreen></iframe>
> $AC$ Pour √ßa, il nous faudrait un test end-to-end, un test qui nous assure que le parapluie remplit bien sa fonction premi√®re.
> On pourrait simuler de la pluie pour v√©rifier que le parapluie nous prot√®ge bien.

## text white
De <strong>bout en bout (e2e)</strong> l'usage du parapluie
> #JP# Ok, maintenant on est encore plus s√ªr que notre parapluie est de qualit√©.
> $AC$ On pourrait envoyer des nouveaux mod√®les de parapluie pour voir si on a des retours positifs / n√©gatifs.

## text white
Du <strong>canary testing</strong> sur les nouveaux mod√®les
> _#JP#_ Yes, on appelle en g√©n√©ral √ßa du canary testing, on envoie un petit groupe de personnes pour tester un nouveau produit.

## text
ü§î
> $AC$ Normalement vous devriez vous demander "Pourquoi ces deux l√† me parlent de parapluie ?"
> #JP# C'est une tr√®s bonne question.
> $AC$ On a voulu vous montrer que les tests, c'est pas juste une question de techno, c'est aussi une question de r√©flexion.
> Par cette parabole....douteuse... on vous a partag√© quelques d√©finitions sur des proc√©d√©s de tests qui r√©pondent √† diff√©rents besoin.
> #JP# Il est possible que les d√©finitions qu'on vient de donner ne vous plaisent pas.
> On constate qu'il existe souvent des grandes diff√©rences entre les d√©finitions de tests unitaires, d'int√©gration et d'end-to-end, de mock etc.
> $AC$ On ne cherche pas ici √† donner des d√©finitions universelles, on se met juste d'accord sur ce qu'on entend par ces termes et sur les besoins auxquels ils r√©pondent.
> Clairement, si vous les appelez autrement, il y a pas de soucis.

## text
Quelle <strong>strat√©gie</strong> alors pour mes tests ?
> #JP# Maintenant qu'on a fait les zozo avec notre parapluie, quel strat√©gie de test on peut appliquer √† nos projets ? 
> Quand on vous parle de conception / structuration des tests, vous avez certainement un mod√®le en t√™te.
> Vous avez probablement entendu parl√© de la pyramide des tests.
> C'est le mod√®le le plus connu, mais le connaissez-vous vraiment ?

## text white
La pyramide des tests
> $AC$ La pyramide des tests dans votre t√™te c'est quoi ?
> Quand on a fouill√© avec Jules, on a trouv√© √©norm√©ment de repr√©sentation de celle-ci et vous aller voir c'est assez comique.
> Aller, soir√©e diapositives, voici donc 3 exemples trouv√©s sur internet.

## media fade-from contain white
<img src="src/img/pyramide/pyramide-1.png" />

> $AC$ Bel arc en ciel n'est-ce pas ? 
> On voit une notion de vitesse et peut-√™tre de scope.

## media fade-from contain white
<img src="src/img/pyramide/pyramide-2.png" />

> $AC$ Ici on voit des "solutions tests", qui ne sont pas d√©finis dans l'article connexe.
> Pourquoi pas des "Problem tests" ?

## media fade-from contain white
<img src="src/img/pyramide/pyramide-3.png" />

> $AC$ Celle-l√† je l'aime bien, elle a le bon go√ªt du fait maison.
> Ici E2E pour end-to-end
> #JP# Bon on pourrait jouer des heures √† vous montrer des pyramides, mais on va pas le faire.
> 3 √©tages, parfois 2 √©tages, plusieurs dimensions, clairement le mod√®le est fortement interpret√©.
> Alors sur quoi pouvons-nous nous baser pour le modele de la pyramide des tests ?

## text white
Mais en vrai √ßa vient d'o√π ?
> $AC$ Le r√©flexe qu'on devrait avoir ce serait de savoir d'o√π √ßa vient au d√©part.
> Et m√™me...

## text white
Mais en vrai √ßa vient <strong>de qui</strong> ?
> $AC$ de qui !
> D√©j√†, contrairement √† ce qu'on peut lire dans beaucoup d'article, non ce n'est pas Martin Fowler.

## media contain logo
<img src="src/img/mike-cohn.png">

> #JP# C'est Mike Cohn, dans son livre "Succeeding with Agile: Software Development using Scrum".

## media contain
<img src="src/img/succeeding-with-agile.png">

>  #JP# Dans ce livre il d√©fini un mod√®le en forme de pyramide pour comparer 3 typologies de tests tout en comparant leur facilit√© de mise en oeuvre et leur capaciter √† apporter du feedback rapidement. 
> Voyons √ßa un peu de plus pr√®s.

## media fade-from contain logo
<img src="src/img/pyramide/pyramide-mike-cohn.png" />

> D√©j√† dans sa pyramide, dans le chapitre il explique qu'il place que des tests automatis√©s.
> Dans le mod√®le de base il ne compare pas les tests √† la main avec des tests automatis√©s.
> Il place en haut de la pyramide les tests UI, il ne parle pas sp√©cifiquement de test E2E, il parle juste de tests d'interface.
> Ensuite il place les tests de service, et enfin les tests unitaires.
> #JP# Il explique que les tests UI sont les plus couteux √† mettre en place, les plus lents, les plus fragiles.
> Rappel, en 2009 je suis en CE1, et clairement pour tester de mani√®re automatis√©e une interface graphique c'est pas la joie.
> On est pas loin de taper deux silex entre eux pour faire du feu.
> $AC$ J'ai commenc√© a faire des tests automatis√©s en 2014, et m√™me √† cette √©poque l√†, on gal√©rait.
> Si je vous parle de Selenium, il y a peut-√™tre quelques frissons qui vont se propager dans la salle.


## text
Les limites de ce mod√®le
> #JP# Ce mod√®le qui connait beaucoup de d√©rives nous parait un peu d√©pass√©.
> Pour plusieurs raisons qu'on justifiera par la suite.
> $AC$ D√©j√† en 2025 il est bien plus facile de setup des tests d'UI.
> Voir m√™me aussi facile que des Test unitaires.
> Que les tests unitaires peuvent √™tre rapide √† setup mais qu'ils souffrent souvent d'overspecifying.

## text
Un mod√®le de <strong>2009</strong>
> #JP# On ne va pas jeter la pierre √† Mike Cohn, lui m√™me reconnait dans son livre que cette pyramide fait sens notamment li√© au contexte technologique.
> $AC$ Pour autant on voit encore ce mod√®le expos√©, transform√©, avec plus o√π moins d'√©tages sans pour autant qu'on se pr√©occupe du message initiale.

## media contain white todo
<img src="https://cookbook.marmicode.io/assets/images/honeycomb-test-model-033e461521df0d8b1cf5bf7dc22e1380.png">

> $AC$ Pour nous, une fa√ßon de mod√©liser qui nous semble pertinente aujourd'hui, c'est le mod√®le exprim√© dans un article de Younes Jaaidi de Marmicode avec un hexagone des tests.
> Ce mod√®le r√®gle deux parties floues de la pyramide des tests qu'on a pu voir.
> #JP# D'abord, il l√®ve l'ambigu√Øt√© entre les tests d'int√©gration et les tests unitaires, en les regroupant sous le terme de tests "narrow". Ensuite, il d√©place ces tests unitaires vers le centre de l'hexagone, pour montrer qu'ils sont au c≈ìur de la strat√©gie de test, mais qu'ils ne sont pas la base de tout et qu'ils ne sont pas suffisants.

## text white
üî¨
> $AC$ Maintenant voyons un peu ce qui se passe dans le monde r√©el, en sortant du mod√®le de Mike Cohn.
> J'ai mont√© un institut de sondage Pipo forg√© par nos biais de confirmation et quelques √©changes que nous avons eu depuis plusieurs ann√©es quand on pose la question.
> Soit en meetup, en conf√©rence, en menant des audits, on faisant des entretiens, en regardant les r√©sultats de sondages et d'enqu√™tes.
> #JP# On a souvent pos√© la questions: "Et vous, comment vous testez ?"
> Voici donc quelques typologies de r√©ponses observ√©es, on va essayer de sainement les critiquer au sens propre du terme.
> En essayant de montrer les limites de ces approches.

## poster fade-to
==========
_"Nous on ne test pas, on a pas le temps."_
<img src="src/img/chaplin.gif" style="max-height: 300px;" />
xxxxxxxxxx
xxxxxxxxx
==========
xxxxxxxxxx
xxxxxxxxxx
----------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxx
==========
> $AC$ Malheureusement la r√©ponse qu'on entend le plus souvent.
> Nous on teste pas, celle-ci, je l'aime particuli√®rement.
> Souvent elle est teint√© de frustration, de manque de temps, de pression, de manque de comp√©tence, de manque de ressource, etc.
> R√©guli√®rement je r√©ponds pour d√©tendre un peu "Mais du coup vous faites que du code qui marche du premier coup ?".
> #JP# Vous allez nous dire, on abuse, il y en a pas tant que √ßa des √©quipes qui ne testent pas.
> Alors pour s'y int√©resser, il y a relativement peu d'√©tude statistique fiable sur le sujet.
> Mais il y en a une d√©j√† qu'on pourrait citer.
> Vous connaissez le State of JS ? 

## media
<img src="src/img/state-of-js.jpg" screenshot-url="https://stateofjs.com/en-US"/>

> #JP# C'est une √©tude qui est men√©e chaque ann√©e sur l'√©cosyst√®me JS.
> Il y a un chapitre qui s'int√©resse aux outils de tests voici donc quelques r√©sultats.

## barchart unit="%" max="50"
State of JS 2024
O outil : 21 red
1 outil : 9
2 outils : 10
3 outils : 10
4 outils : 10
5+ outils : 40

> Voici ce que d√©clarent les r√©pondants √† l'√©tude.
> D√©ja on peut se rassurer, les √©quipes qui ne testent pas sont minoritaires.
> On a cependant presque un quart qui n'utilise aucun outil de test.

## poster fade-to
==========
_"Nous on ne test pas, on a pas le temps."_
<img src="src/img/chaplin.gif" style="max-height: 300px;" />
xxxxxxxxxx
xxxxxxxxx
==========
xxxxxxxxxx
xxxxxxxxxx
----------
21% n'automatisent pas leurs tests
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxx
==========
> Ne pas automatiser ses tests c'est souvent priv√©li√©gier du temps humain de v√©rification.
> Il n'y a pas de magie, les √©quipes de devs vont manuellement tester lors de leur d√©veloppement, les √©quipes produits, les √©quipes de tests parfois.
> #JP# C'est souvent une question de priorit√©, de culture, de comp√©tence, de ressource, de maturit√©, etc.
> Ces approches sans automatisations peuvent paraitre de prime abord plus rapide, mais elles sont souvent plus couteuses √† long terme.
> La confiance sur le code va reposer sur la m√©moire humaine, la documentation, la communication.
> $AC$ Clairement la strat√©gie du **rien** ne nous parait pas viable mis √† part dans un mode draft ou on sait qu'on va jeter explicitement ce qu'on produit.
> On entend parfois des √©quipes qui font reposer le test manuels sur des √©quipe QA qui ont toute la charge de la qualit√©.
> C'est le mod√®le qu'on appelle parfois le "Ice Cream Cone" pos√© par **Alister B Scott**.

## media contain white
<img src="src/img/pyramide/ice-cream.png"/>

> #JP# C'est souvent une strat√©gie de test tr√®s co√ªteuse, qui va ralentir le d√©veloppement, qui va √™tre source de frustration.
> On ne dit pas que d'avoir des tests manuels c'est mal hein, on va juste dire que centraliser sa strat√©gie de tests dessus n'est pas pour nous une bonne id√©e.
> √áa ne passera pas √† l'√©chelle.

## poster fade-to
==========
_"On fait du Jest / Testing Library / Cypress / ..."_
xxxxxxxxxx
xxxxxxxxxx
----------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxx
==========
<img src="src/img/scott-blake-wq7oyx_Kx-4-unsplash.jpg" style="min-height: 400px" />
xxxxxxxxxx
xxxxxxxxxx
==========
> $AC$ En deuxi√®me position des r√©ponses √† la question "Comment vous testez ?" on a souvent des r√©ponses plus techniques.
> On nous r√©pond des technos de tests, des outils, des librairies, des frameworks.
> Comme si ces outils √©taient une fin en soi. 
> Soyons clair des outils de tests c'est bien, mais savoir clairement "Qu'est-ce qu'on teste ?" est mieux.

## poster fade-to
==========
_"On fait du Jest / Testing Library / Cypress / ..."_
xxxxxxxxxx
xxxxxxxxxx
----------
Faire des tests, juste pour en faire
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxx
==========
<img src="src/img/scott-blake-wq7oyx_Kx-4-unsplash.jpg" style="min-height: 400px" />
xxxxxxxxxx
xxxxxxxxxx
==========
> #JP# On a r√©guli√®rement cette r√©ponse quand la strat√©gie de test semble impos√©e de mani√®re tr√®s solutionniste.
> On fait des tests parce qu'on nous a dit d'en faire / qu'on nous a dit que c'√©tait bien.
> Est-ce que ces outils, ces librairies vous aident ou au contraire vous infliges de l'aide.
> Clairement vous ici dans la salle, si vous regardez vos tests, √† quoi vous sont ils utiles ?
> Qu'est-ce qu'ils vous apportent au jour le jour ?

## poster fade-to
==========
_"On fait du Jest / Testing Library / Cypress / ..."_
xxxxxxxxxx
xxxxxxxxxx
----------
Faire des tests, juste pour en faire
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxx
==========
<img src="src/img/scott-blake-wq7oyx_Kx-4-unsplash.jpg" style="min-height: 400px" />
Qu'est-ce que vous testez ?
xxxxxxxxxx
==========
> #JP# On a r√©guli√®rement cette r√©ponse quand la strat√©gie de test semble impos√©e de mani√®re tr√®s solutionniste.
> On fait des tests parce qu'on nous a dit d'en faire / qu'on nous a dit que c'√©tait bien.
> Est-ce que ces outils, ces librairies vous aident ou au contraire vous infliges de l'aide.
> Clairement vous ici dans la salle, si vous regardez vos tests, √† quoi vous sont ils utiles ?
> Qu'est-ce qu'ils vous apportent au jour le jour ?

## poster fade-to
==========
_"Nous on teste absolument tout, coverage √† 100%"_
xxxxxxxxxx
xxxx
<img src="src/img/bianca-ackermann-fUIDHNjwbto-unsplash.jpg" />
xxxxxxxxxx
==========
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxx
------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxx
==========
> #JP# En troisi√®me position, on va retrouver des √©quipes qui ont une strat√©gie de test tr√®s quantitative.
> Pas forc√©ment associ√© √† des pratiques TDD, BDD, on retrouve cependant de plus en plus d'√©quipe qui utilisent des indicateurs de coverage de test pour objectiver leur strat√©gie de tests.
> $AC$ On a souvent des √©quipes qui vont se fixer des objectifs de coverage de test, 80%, 90%, 100%.
> Le coverage c'est comptabiliser le ratio de lignes de code qui sont ex√©cut√©es par vos tests.
> √áa ne vous dit pas du tout si vos tests sont bons, si ils sont pertinents, si ils sont efficaces.
> Est-ce que cependant le coverage est une bonne m√©trique ?
> Est-ce que chacune des lignes de votre codebase m√©rite d'√™tre test√©e avec la m√™me pr√©cision, la m√™me rigeure, le m√™me d√©tail ?

## poster fade-to
==========
_"Nous on teste absolument tout, coverage √† 100%"_
xxxxxxxxxx
xxxx
<img src="src/img/bianca-ackermann-fUIDHNjwbto-unsplash.jpg" />
xxxxxxxxxx
==========
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
------
Le coverage n'est pas un indicateur de qualit√© de tests
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxx
==========
> #JP# Le coverage n'est qu'un indicateur de quantit√© et de ratio, il ne donne aucune indication sur la qualit√© des tests.
> Il est tr√®s facile de faire des tests qui couvrent 100% d'une fonction / class / module mais qui ne font aucun expect par exemple.
> Une strat√©gie quantitative va √©galement vous apporter des probl√®mes de scalabilit√© de vos tests.
> #AC# On se retrouve avec √©norm√©ment de tests √† faire tourner ce qui va ralentir votre CI, ralentir votre d√©veloppement, le d√©lai pour avoir du feedback en sera que plus long.

## poster fade-to
==========
_"Nous on teste absolument tout, coverage √† 100%"_
xxxxxxxxxx
xxxx
<img src="src/img/bianca-ackermann-fUIDHNjwbto-unsplash.jpg" />
xxxxxxxxxx
==========
xxxxxxxxxx
xxxxxxxxxx
Trop de tests, CI trop lente
------
Le coverage n'est pas un indicateur de qualit√© de tests
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxx
==========
> #AC# Avoir beaucoup de tests √ßa peut devenir un enfer, attendre 40min pour avoir du feedback √ßa peut √™tre tr√®s compliqu√©.
> Est-ce que run **tous** les tests **tout le temps** est une bonne id√©e ?
> On verra ensemble des techniques pour √©viter √ßa.

## poster fade-to todo
==========
_"On teste que cette partie l√†, le reste c'est pas important"_
xxxxxxxxxx
xxxx
xxxxxxxxxx
xxxxxxxxxx
==========
xxxxxxxxxx
xxxxxxxxxx
------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxx
==========

## text
Quoi en penser ?
<br/>
<br/>
ü§î
> $AC$ Bon, d'apr√®s ce sondage DIY il nous laisse l'impression que les dev ont pas tous en t√™te toutes les raisons et les b√©n√©fices qu'on tire du fait de tester.

## media logo white
<img src="https://static.vecteezy.com/system/resources/previews/026/551/422/non_2x/exit-full-screen-pixelated-ui-icon-video-player-view-display-get-out-fullscreen-mode-editable-8bit-graphic-element-outline-isolated-user-interface-image-for-web-mobile-app-retro-style-vector.jpg"/>

> $AC$ En fait, si on d√©zoome et qu'on se demande **pourquoi** on teste, on compte 5 piliers majeurs qui nous poussent √† √©crire des tests.

## kiosk
> #JP# On va vous faire participer un peu ! Avec un kiosk avec 5 mots √† r√©v√©ler qui sont pour nous les 5 piliers du testing. On va voir si on peut retrouver ensemble les 5 piliers.
> On va essayer de prendre vos r√©ponses et de voir si on peut les faire correspondre √† nos piliers.
> Selon vous, pourquoi on teste nos applications ?

> Rouge : Conformit√©
> On veut s'assurer que notre application respecte les sp√©cifications, les contraintes, les normes, les standards, les r√©glementations, les lois, etc. En bref, que le code, il r√©pond bien √† nos attentes.
> Bleu : Documenter
> Les tests sont une forme de documentation, ils laissent une trace des comportements de notre code dans diff√©rentes situations.
> Magenta : Reproductibilit√©
> Les tests permettent de reproduire des comportements, de s'assurer que le code fonctionne toujours comme pr√©vu m√™me dans des cas complexes.
> Jaune : Int√©grit√©
> Ils permettent d'assurer un √©tat stable de l'application, dans l'historique du code, dans les branches, dans les environnements, etc.  
> Vert : Stabilit√©
> Est-ce que le diff que j'apporte r√©pond bien √† tous les tests d√©j√† en place ? Est-ce que je casse pas quelque chose ? 
 
> $AC$ Pour nous voil√† les 5 piliers qui nous poussent √† √©crire des tests. Il faut garder √† l'esprit qu'on met en place
> tout √ßa pour acc√©lerer notre d√©veloppement. D'ailleurs, si vous sentez qu'un ou plusieurs de ces piliers sont des sujets
> dans vos projets, c'est peut-√™tre le moment pour voir s'il n'y pas un besoin de voir ou revoir la strat√©gie de vos tests.

## poster todo
journal section trucs et astuces

> #JP# Dans les conseils qu'on peut vous donner pour concevoir une strat√©gie de test, voil√† quelques id√©es et astuces qu'on peut vous donner.

## text
Ne mesurez pas le <strong>coverage</strong>
> $AC$ "Ne mesurez pas le coverage". Le coverage pour rappel, c'est le ratio de ligne ex√©cut√©e lors de vos tests. Ca ne mesure en rien la qualit√© de vos tests.

## code
```js
function add(a, b) {
  return a + b;
}

it('should add two numbers and return the result', () => {
    const firstNumber = 1;
    const secondNumber = 2;
    let result = add(firstNumber, secondNumber);
});
```
> #JP# Regarde Antoine, j'ai trouv√© un code avec 100% de coverage. C'est trop bien, mais l√†, il y a un souci √©vident non ?
> $AC$ Oui, il n'y a aucun expect. On a 100% de coverage mais on a pas de test.
> #JP# Pour mesurer la qualit√© de vos tests sans coverage, on peut utiliser des outils de mutation testing.

## text todo
Optez pour du <strong>mutation testing</strong>
todo: completer l'explication
> #JP# L'id√©e en deux phrases, c'est de modifier le code source et de voir si les tests √©chouent. Si les tests qui passent m√™me avec des modifications dans votre code sont des tests inutiles.
> $AC$ Le sujet en lui est tr√®s vaste et on aurait pu passer la conf√©rence enti√®re dessus. On vous invite √† regarder des outils comme Stryker, PIT, etc.

## text todo
todo: ajouter un **related** sur conference du mutation testing

## text todo
Traite ta test base comme ta codebase "how you do one thing is how you do everything"
- s'imposer des r√®gles et les automatis√©s (lint)
- Se reposer sur analyse statique / compilation
> Tester avec le diff avec une architecture d√©coup√©
jest / vitest le fond
nx affected
Sharding
> cat√©goriser et prioriser les tests
> Dans le monde JS, pr√©f√©rer des outils comme Vitest (r√©f√©rence l'article de Younes)
expliquer rapidement pourquoi
> Setup une stack E2E est facile 2025 et les tests mettent beaucoup de temps qu'√† une √©poque Selenium
> Dans des tests d'interface web, un truc qui prend le plus de temps c'est l'http. _DEMO_ playwright overhead
> en plus √ßa d√©bloque la possibilit√© de tester des comportement √† la marge (latence / erreur)
> les tests UI √ßa coutent plus aussi cher qu'a l'√©poque, playwright est simple √† setup et rapide (ce qui c√¥ute c'est ce qu'on teste)
> rationaliser sa quantit√© de test -> pour un freelance c'est pas n√©cessaire de tester parce que pas gain https://xkcd.com/1205/

## poster main
Merci beaucoup !
==========
Oubliez pas de donner du feedback !
xxxxxxxxxx
xxxxxxxxxx
xxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxx
==========
xxxxxxxxxx
xxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxx
==========
<img class="contain" src="src/img/qrcode.png"/>
==========
> @00:45:00@

## credits

R√©f√©rences :

* D√©p√¥t de la pr√©sentation : https://github.com/jpoissonnet/talk-test/

Liens :
* state of js : https://stateofjs.com/en-US
* Alister B Scott, Ice Cream model : https://alisterscott.github.io/TestingPyramids.html

* Designing a Pragmatic Testing Strategy : https://cookbook.marmicode.io/angular/pragmatic-testing-strategy/
Images :

* photos des parapluie : https://www.neyrat.fr/
* pyramide des tests 1 : https://thumbs.dreamstime.com/b/pyramide-de-test-avec-interface-utilisateur-tests-d-int%C3%A9gration-et-unitaires-essai-vecteur-unitaire-282317017.jpg
* pyramide des tests 2 : https://blog.atinternet.com/wp-content/uploads/2020/06/ROI-test.jpg
* pyramide des tests 3 : https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IA6N133_wkTin6DMq30u0w.png
* mike cohn : https://upload.wikimedia.org/wikipedia/commons/a/ac/WEB_RES-Mike_Cohn-%C2%A9-2016-Hows_Your_Headshot-6.jpg
* image de chantier : https://unsplash.com/fr/photos/homme-en-veste-grise-et-orange-tenant-un-appareil-photo-reflex-numerique-vert-et-noir-pendant-la-journee-wq7oyx_Kx-4

Polices :

* Yanone Kaffeesatz : https://fonts.google.com/specimen/Yanone+Kaffeesatz
* Just Another Hand : https://fonts.google.com/specimen/Just+Another+Hand
* Boogaloo : https://fonts.google.com/specimen/Boogaloo
* Interstate : https://fonts.adobe.com/fonts/interstate
* Sufler : https://www.dafontfree.io/sufler-font/
* OperatorMono : https://www.typography.com/blog/introducing-operator

Remerciements :

* Hubert Sablonni√®re : pour lui m√™me et ses outils hyper pratiques pour les slides
* Jules : pour sa patience et sa pers√©v√©rance malgr√©s ses cours en parall√®le
