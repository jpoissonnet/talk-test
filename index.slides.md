---
author:
author-twitter:
author-company:
event: Snowcamp
city: Grenoble
date: 23 janvier 2025
---

# Tester c'est tricher

## blank black
> @00:00:00@
> #JP# Dis voir Antoine, tu devrais peut-√™tre leur expliquer pourquoi tu te trimbale avec un parapluie alors qu'il ne pleut pas ici.
> $AC$ tu sais, on est jamais trop prudent, imagine il pleut et bien tu ferais pas le malin.
> #JP# T'as pens√© √† porter un Kway dessous histoire d'√™tre sur ?
> $AC$ Malin j'y avais pas trop pens√©...
> Bon aller, on est pas la pour √ßa.

## poster fade-from main
Tester c'est tricher
==========
Antoine Caron _Engineering Manager @Scaleway_ !
xxxxxxxxxx
xxxxxxxxxx
xxxx
xxxxxxxxxx
xxxxxxxx
==========
xxxxxxxxxx
xxxxxx
------
Jules Poissonnet _Frontend Dev @Bedrock&nbsp;Streaming_
xxxxxxxxxx
xxxxxxxxxx
==========
xxxxxxxxxx
<img src="src/img/grenoble.png"/>
xxxxxxxxxx
xxxxxxxxx
==========
> $AC$ Bonjour √† toutes et tous, j'esp√®re que vous allez bien et que cette journ√©e se d√©roule comme vous l'esp√©riez.
> Je m'appelle Antoine Caron et je suis Engineering manager Frontend chez Scaleway, vous m'avez peut-√™tre vu l'ann√©e pass√©e vous parler de Gzip.
> #JP# Et moi c'est Jules Poissonnet, Frontend Dev chez Bedrock Streaming.
> Si l'autre malin avec son parapluie et moi-m√™me sommes ici aujourd'hui, c'est pour vous parler de tests.
> C'est un sujet qui nous int√©resse beaucoup et qu'on trouve souvent mal abord√©.
> $AC$ On esp√®re avec cette pr√©sentation ouvrir un peu vos chakras sur la notion de testing.
> Souvent abord√© de mani√®re dogmatique, on va essayer une approche plus pragmatique
> #JP# Que vous fassiez du frontend, du backend, du mobile ou de l'embarqu√©, des "tests" ou pas, on souhaite vous proposer quelques r√©fl√©xions / conseils et approches qui pourraient √™tre utiles et concr√®tes.
> $AC$ Alors pourquoi "Tester c'est tricher", tricher c'est enfreindre des r√®gles √©tablis, des conventions, des normes.
> Pour nous il existe des normes, des strat√©gies de tests qui sont souvent mal comprises, mal appliqu√©es, mal interpr√©t√©es.
> #JP# On va essayer de vous montrer que les tests c'est pas juste une question de techno, c'est aussi une question de r√©flexion, de culture, de priorit√©.

## blank white 
> $AC$ ...Bon, plongeons nous dans un univers qui n'est pas le d√©velopment pour voir ce qu'on peut en tirer
> Il nous faudrait un objet, par exemple.
> #JP# Un parapluie tient, au moins il sera utile.

## media fade-from contain
<img src="src/img/parapluie-ouvert.jpg"/>

> $AC$ Super id√©e, j'adore les parapluies, c'est tellement pratique.
> Mais attends, on est dev front, j'ai aucune id√©e des techno de test de parapluie.
> #JP# La premi√®re chose que tu te demande c'est "Quelles sont les techno ?"
> Perso, je pr√©f√®re me demander...

## text fade-from
ü§î Comment on teste un parapluie ? 
> $AC$ C'est pas b√™te √ßa, on pourrait m√™me se poser la question de ...
> #JP# Et m√™me aller plus loin

## text
Qu'est-ce qu'on teste ?
> $AC$ D√©j√†, il nous faut une mati√®re imperm√©able, sinon c'est pas tr√®s utile.

## media fade-from contain
<img src="src/img/toile.png"/>

> #JP# D√©j√† il nous faut donc un proc√©d√© qui nous permet de tester unitairement la toile du parapluie.
> $AC$ Ah oui je vois o√π tu veux en venir, un genre de test unitaire o√π on s'occupe uniquement de la toile.
> √áa nous permettrait d'√©viter de fabriquer un parapluie qui nous prot√®ge pas du tout de la pluie.

## text white
<strong>Test unitaire</strong> de la toile
> $AC$ Clairement ce serait d√©j√† bien, mais toi comme moi, on sait que le principale souci des parapluies...
> #JP# C'est que le m√©canisme est souvent fragile et fini par casser, le rendant inutilisable.
> Il nous faudrait un proc√©d√© pour tester la robustesse du m√©canisme.

## media fade-from contain
<img src="src/img/mechanisme.png"/>

> Il nous faudrait ouvrir et fermer le m√©canisme un grand nombre de fois pour s'assurer qu'il ne casse pas.
> $AC$ Un peu comme un test d'int√©gration, on v√©rifie qu'un ensemble des pi√®ces fonctionnent bien ensemble.

## text white
<strong>Test d'int√©gration</strong> du m√©canisme
> #JP# Oui completement, ce serait d√©j√† pas mal, mais on sait tous que le vent est l'ennemi num√©ro 1 des parapluies.
> $AC$ Mais comment on fait pour tester √ßa ? On va pas arreter la production tant qu'il n'y a pas de vent.
> #JP# On peut surement faire passer les parapluies en soufflerie, pour s'assurer qu'il tiennent le coup.
> $AC$ Ah oui, la soufflerie, ce serait comme un test avec des mocks.

## text white
On <strong>mock</strong> le vent avec la soufflerie
> #JP# Tout √ßa, √ßa nous donne un parapluie hydrophobe, robuste et r√©sistant au vent.
> Mais √ßa nous assure toujours pas qu'on soit √† l'abris de la pluie.
> $AC$ En effet, en testant morceaux par morceaux notre parapluie, on n'est pas √† l'abris de ne pas l'√™tre.

## media fade-from logo
<iframe src="https://giphy.com/embed/BmQPKjwhScjdK" frameBorder="0" allowFullScreen></iframe>
> $AC$ Pour √ßa, il nous faudrait un test end-to-end, un test qui nous assure que le parapluie remplit bien sa fonction premi√®re.
> On pourrait simuler de la pluie pour v√©rifier que le parapluie nous prot√®ge bien.

## text white
De <strong>bout en bout (e2e)</strong> l'usage du parapluie
> #JP# Ok, maintenant on est encore plus s√ªr que notre parapluie est de qualit√©.
> $AC$ On pourrait envoyer des nouveaux mod√®les de parapluie pour voir si on a des retours positifs / n√©gatifs.

## text white
Du <strong>canary testing</strong> sur les nouveaux mod√®les
> _#JP#_ Yes, on appelle en g√©n√©ral √ßa du canary testing, on envoie un petit groupe de personnes pour tester un nouveau produit.

## text
ü§î
> $AC$ Normalement vous devriez vous demander "Pourquoi ces deux l√† me parlent de parapluie ?"
> #JP# C'est une tr√®s bonne question.
> $AC$ On a voulu vous montrer que les tests, c'est pas juste une question de techno, c'est aussi une question de r√©flexion.
> Par cette parabole....douteuse... on vous a partag√© quelques d√©finitions sur des proc√©d√©s de tests qui r√©pondent √† diff√©rents besoin.
> #JP# Il est possible que les d√©finitions qu'on vient de donner ne vous plaisent pas.
> On constate qu'il existe souvent des grandes diff√©rences entre les d√©finitions de tests unitaires, d'int√©gration et d'end-to-end, de mock etc.
> $AC$ On ne cherche pas ici √† donner des d√©finitions universelles, on se met juste d'accord sur ce qu'on entend par ces termes et sur les besoins auxquels ils r√©pondent.
> Clairement, si vous les appelez autrement, il y a pas de soucis.

## text
Quelle <strong>strat√©gie</strong> alors pour mes tests ?
> #JP# Maintenant qu'on a fait les zozo avec notre parapluie, quel strat√©gie de test on peut appliquer √† nos projets ? 
> Quand on vous parle de conception / structuration des tests, vous avez certainement un mod√®le en t√™te.
> Vous avez probablement entendu parl√© de la pyramide des tests.
> C'est le mod√®le le plus connu, mais le connaissez-vous vraiment ?

## text white
La pyramide des tests
> $AC$ La pyramide des tests dans votre t√™te c'est quoi ?
> Quand on a fouill√© avec Jules, on a trouv√© √©norm√©ment de repr√©sentation de celle-ci et vous aller voir c'est assez comique.
> Aller, soir√©e diapositives, voici donc 3 exemples trouv√©s sur internet.

## ext-content
<img src="src/img/pyramide/pyramide-1.png" />
Pyramide des tests mod√®le 1

> $AC$ Bel arc en ciel n'est-ce pas ? 
> On voit une notion de vitesse et peut-√™tre de scope.

## ext-content
<img src="src/img/pyramide/pyramide-2.png" />
Pyramide des tests mod√®le 2

> $AC$ Ici on voit des "solutions tests", qui ne sont pas d√©finis dans l'article connexe.
> Pourquoi pas des "Problem tests" ?

## ext-content white
<img src="src/img/pyramide/pyramide-3.png" />
Pyramide des tests mod√®le 3 / 10000

> $AC$ Celle-l√† je l'aime bien, elle a le bon go√ªt du fait maison.
> Ici E2E pour end-to-end
> #JP# Bon on pourrait jouer des heures √† vous montrer des pyramides, mais on va pas le faire.
> 3 √©tages, parfois 2 √©tages, plusieurs dimensions, clairement le mod√®le est fortement interpret√©.
> Alors sur quoi pouvons-nous nous baser pour le modele de la pyramide des tests ?

## text white
Mais en vrai √ßa vient d'o√π ?
> $AC$ Le r√©flexe qu'on devrait avoir ce serait de savoir d'o√π √ßa vient au d√©part.
> Et m√™me...

## text white
Mais en vrai √ßa vient <strong>de qui</strong> ?
> $AC$ de qui !
> D√©j√†, contrairement √† ce qu'on peut lire dans beaucoup d'article, non ce n'est pas Martin Fowler.

## media contain logo
<img src="src/img/mike-cohn.png">
> #JP# C'est Mike Cohn, dans son livre "Succeeding with Agile: Software Development using Scrum".

## ext-content
<img src="src/img/succeeding-with-agile.png">

>  #JP# Dans ce livre il d√©fini un mod√®le en forme de pyramide pour comparer 3 typologies de tests tout en comparant leur facilit√© de mise en oeuvre et leur capaciter √† apporter du feedback rapidement. 
> Voyons √ßa un peu de plus pr√®s.

## ext-content contain
<img src="src/img/pyramide/pyramide-mike-cohn.png" />
Pyramide des tests de <strong>Mike Cohn</strong>

> D√©j√† dans sa pyramide, dans le chapitre il explique qu'il place que des tests automatis√©s.
> Dans le mod√®le de base il ne compare pas les tests √† la main avec des tests automatis√©s.
> Il place en haut de la pyramide les tests UI, il ne parle pas sp√©cifiquement de test E2E, il parle juste de tests d'interface.
> Ensuite il place les tests de service, et enfin les tests unitaires.
> #JP# Il explique que les tests UI sont les plus couteux √† mettre en place, les plus lents, les plus fragiles.
> Rappel, en 2009 je suis en CE1, et clairement pour tester de mani√®re automatis√©e une interface graphique c'est pas la joie.
> On est pas loin de taper deux silex entre eux pour faire du feu.
> $AC$ J'ai commenc√© a faire des tests automatis√©s en 2014, et m√™me √† cette √©poque l√†, on gal√©rait.
> Si je vous parle de Selenium, il y a peut-√™tre quelques frissons qui vont se propager dans la salle.

## text
Les limites de ce mod√®le
> #JP# Ce mod√®le qui connait beaucoup de d√©rives nous parait un peu d√©pass√©.
> Pour plusieurs raisons qu'on justifiera par la suite.
> $AC$ D√©j√† en 2025 il est bien plus facile de setup des tests d'UI.
> Voir m√™me aussi facile que des Test unitaires.
> Que les tests unitaires peuvent √™tre rapide √† setup mais qu'ils souffrent souvent d'overspecifying.

## text
Un mod√®le de <strong>2009</strong>
> #JP# On ne va pas jeter la pierre √† Mike Cohn, lui m√™me reconnait dans son livre que cette pyramide fait sens notamment li√© au contexte technologique.
> $AC$ Pour autant on voit encore ce mod√®le expos√©, transform√©, avec plus o√π moins d'√©tages sans pour autant qu'on se pr√©occupe du message initiale.

## ext-content contain
<img src="src/img/honeycomb-test-model-033e461521df0d8b1cf5bf7dc22e1380.png">
https://cookbook.marmicode.io/angular/pragmatic-testing-strategy/
Designing a Pragmatic Testing Strategy - <strong>Y Jaaidi</strong>

> $AC$ Pour nous, une fa√ßon de mod√©liser qui nous semble pertinente aujourd'hui, c'est le mod√®le exprim√© dans un article de Younes Jaaidi de Marmicode avec un hexagone des tests.
> Ce mod√®le r√®gle deux parties floues de la pyramide des tests qu'on a pu voir.
> #JP# D'abord, il l√®ve l'ambigu√Øt√© entre les tests d'int√©gration et les tests unitaires, en les regroupant sous le terme de tests "narrow". Ensuite, il d√©place ces tests unitaires vers le centre de l'hexagone, pour montrer qu'ils sont au c≈ìur de la strat√©gie de test, mais qu'ils ne sont pas la base de tout et qu'ils ne sont pas suffisants.

## text white
üî¨
> $AC$ Maintenant voyons un peu ce qui se passe dans le monde r√©el, en sortant du mod√®le de Mike Cohn.
> J'ai mont√© un institut de sondage Pipo forg√© par nos biais de confirmation et quelques √©changes que nous avons eu depuis plusieurs ann√©es quand on pose la question.
> Soit en meetup, en conf√©rence, en menant des audits, on faisant des entretiens, en regardant les r√©sultats de sondages et d'enqu√™tes.
> #JP# On a souvent pos√© la questions: "Et vous, comment vous testez ?"
> Voici donc quelques typologies de r√©ponses observ√©es, on va essayer de sainement les critiquer au sens propre du terme.
> En essayant de montrer les limites de ces approches.

## poster fade-to main
Les believers
==========
_"Nous on ne test pas, on a pas le temps."_
<img src="src/img/chaplin.gif" style="max-height: 300px;" />
==========
xxxxxxxxxx
xxxxxxxxxx
----------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxx
==========
> $AC$ Malheureusement la r√©ponse qu'on entend le plus souvent.
> Nous on teste pas, celle-ci, je l'aime particuli√®rement.
> Souvent elle est teint√© de frustration, de manque de temps, de pression, de manque de comp√©tence, de manque de ressource, etc.
> R√©guli√®rement je r√©ponds pour d√©tendre un peu "Mais du coup vous faites que du code qui marche du premier coup ?".
> #JP# Vous allez nous dire, on abuse, il y en a pas tant que √ßa des √©quipes qui ne testent pas.
> Alors pour s'y int√©resser, il y a relativement peu d'√©tude statistique fiable sur le sujet.
> Mais il y en a une d√©j√† qu'on pourrait citer.
> Vous connaissez le State of JS ? 

## ext-content contain
<img src="src/img/state-of-js.jpg" screenshot-url="https://stateofjs.com/en-US"/>
https://stateofjs.com/en-US
State of JS 2024

> #JP# C'est une √©tude qui est men√©e chaque ann√©e sur l'√©cosyst√®me JS.
> Il y a un chapitre qui s'int√©resse aux outils de tests voici donc quelques r√©sultats.

## barchart unit="%" max="50"
State of JS 2024
O outil : 21 red
1 outil : 9
2 outils : 10
3 outils : 10
4 outils : 10
5+ outils : 40

> Voici ce que d√©clarent les r√©pondants √† l'√©tude.
> D√©ja on peut se rassurer, les √©quipes qui ne testent pas sont minoritaires.
> On a cependant presque un quart qui n'utilise aucun outil de test.

## poster main
Les believers
==========
_"Nous on ne test pas, on a pas le temps."_
<img src="src/img/chaplin.gif" style="max-height: 300px;" />
==========
xxxxxxxxxx
xxxxxxxxxx
----------
21% n'automatisent pas leurs tests
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxx
==========
> Ne pas automatiser ses tests c'est souvent priv√©li√©gier du temps humain de v√©rification.
> Il n'y a pas de magie, les √©quipes de devs vont manuellement tester lors de leur d√©veloppement, les √©quipes produits, les √©quipes de tests parfois.
> #JP# C'est souvent une question de priorit√©, de culture, de comp√©tence, de ressource, de maturit√©, etc.
> Ces approches sans automatisations peuvent paraitre de prime abord plus rapide, mais elles sont souvent plus couteuses √† long terme.
> La confiance sur le code va reposer sur la m√©moire humaine, la documentation, la communication.
> $AC$ Clairement la strat√©gie du **rien** ne nous parait pas viable mis √† part dans un mode draft ou on sait qu'on va jeter explicitement ce qu'on produit.
> On entend parfois des √©quipes qui font reposer le test manuels sur des √©quipe QA qui ont toute la charge de la qualit√©.
> C'est le mod√®le qu'on appelle parfois le "Ice Cream Cone" pos√© par **Alister B Scott**.

## ext-content contain
<img src="src/img/pyramide/ice-cream.png"/>
https://alisterscott.github.io/TestingPyramids.html
Ice cream modele - <strong>Alister B Scott</strong>

> #JP# C'est souvent une strat√©gie de test tr√®s co√ªteuse, qui va ralentir le d√©veloppement, qui va √™tre source de frustration.
> On ne dit pas que d'avoir des tests manuels c'est mal hein, on va juste dire que centraliser sa strat√©gie de tests dessus n'est pas pour nous une bonne id√©e.
> √áa ne passera pas √† l'√©chelle.

## poster main
Les technophiles
==========
_"On fait du Jest / Testing Library / Cypress / ..."_
xxxxxxxxxx
xxxxxxxxxx
----------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxx
==========
<img src="src/img/scott-blake-wq7oyx_Kx-4-unsplash.jpg" style="min-height: 400px" />
==========
> $AC$ En deuxi√®me position des r√©ponses √† la question "Comment vous testez ?" on a souvent des r√©ponses plus techniques.
> On nous r√©pond des technos de tests, des outils, des librairies, des frameworks.
> Comme si ces outils √©taient une fin en soi. 
> Soyons clair des outils de tests c'est bien, mais savoir clairement "Qu'est-ce qu'on teste ?" est mieux.

## poster main
Les technophiles
==========
_"On fait du Jest / Testing Library / Cypress / ..."_
xxxxxxxxxx
xxxxxxxxxx
----------
Faire des tests, juste pour en faire
xxxxxxxxxx
xxxxxxxx
==========
<img src="src/img/scott-blake-wq7oyx_Kx-4-unsplash.jpg" style="min-height: 400px" />
==========
> #JP# On a r√©guli√®rement cette r√©ponse quand la strat√©gie de test semble impos√©e de mani√®re tr√®s solutionniste.
> On fait des tests parce qu'on nous a dit d'en faire / qu'on nous a dit que c'√©tait bien.
> Est-ce que ces outils, ces librairies vous aident ou au contraire vous infliges de l'aide.
> Clairement vous ici dans la salle, si vous regardez vos tests, √† quoi vous sont ils utiles ?
> Qu'est-ce qu'ils vous apportent au jour le jour ?

## poster main
Les technophiles
==========
_"On fait du Jest / Testing Library / Cypress / ..."_
xxxxxxxxxx
----------
Faire des tests, juste pour en faire
xxxxxxxxxx
Qu'est-ce que vous testez ?
xxxxxxxxxx
==========
<img src="src/img/scott-blake-wq7oyx_Kx-4-unsplash.jpg" style="min-height: 400px" />
==========
> #JP# On a r√©guli√®rement cette r√©ponse quand la strat√©gie de test semble impos√©e de mani√®re tr√®s solutionniste.
> On fait des tests parce qu'on nous a dit d'en faire / qu'on nous a dit que c'√©tait bien.
> Est-ce que ces outils, ces librairies vous aident ou au contraire vous infliges de l'aide.
> Clairement vous ici dans la salle, si vous regardez vos tests, √† quoi vous sont ils utiles ?
> Qu'est-ce qu'ils vous apportent au jour le jour ?

## poster main
Les Sceptiques
==========
_"Nous on teste absolument tout, coverage √† 100%"_
xxxxxxxxxx
<img src="src/img/bianca-ackermann-fUIDHNjwbto-unsplash.jpg" />
==========
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxx
------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxx
==========
> #JP# En troisi√®me position, on va retrouver des √©quipes qui ont une strat√©gie de test tr√®s quantitative.
> Pas forc√©ment associ√© √† des pratiques TDD, BDD, on retrouve cependant de plus en plus d'√©quipe qui utilisent des indicateurs de coverage de test pour objectiver leur strat√©gie de tests.
> $AC$ On a souvent des √©quipes qui vont se fixer des objectifs de coverage de test, 80%, 90%, 100%.
> Le coverage c'est comptabiliser le ratio de lignes de code qui sont ex√©cut√©es par vos tests.
> √áa ne vous dit pas du tout si vos tests sont bons, si ils sont pertinents, si ils sont efficaces.
> Est-ce que cependant le coverage est une bonne m√©trique ?
> Est-ce que chacune des lignes de votre codebase m√©rite d'√™tre test√©e avec la m√™me pr√©cision, la m√™me rigeure, le m√™me d√©tail ?

## poster main
Les Sceptiques
==========
_"Nous on teste absolument tout, coverage √† 100%"_
xxxxxxxxxx
<img src="src/img/bianca-ackermann-fUIDHNjwbto-unsplash.jpg" />
==========
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
------
Le coverage n'est pas un indicateur de qualit√© de tests
xxxxxxxxxx
xxxxxxx
==========
> #JP# Le coverage n'est qu'un indicateur de quantit√© et de ratio, il ne donne aucune indication sur la qualit√© des tests.
> Il est tr√®s facile de faire des tests qui couvrent 100% d'une fonction / class / module mais qui ne font aucun expect par exemple.
> Une strat√©gie quantitative va √©galement vous apporter des probl√®mes de scalabilit√© de vos tests.
> #AC# On se retrouve avec √©norm√©ment de tests √† faire tourner ce qui va ralentir votre CI, ralentir votre d√©veloppement, le d√©lai pour avoir du feedback en sera que plus long.

## poster main
Les Sceptiques
==========
_"Nous on teste absolument tout, coverage √† 100%"_
xxxxxxxxxx
<img src="src/img/bianca-ackermann-fUIDHNjwbto-unsplash.jpg" />
==========
xxxxxxxxxx
La CI qui met 2 heures.
------
Le coverage n'est pas un indicateur de qualit√© de tests
xxxxxxxxxx
xxxxxxx
==========
> #AC# Avoir beaucoup de tests √ßa peut devenir un enfer, attendre 40min pour avoir du feedback √ßa peut √™tre tr√®s compliqu√©.
> Est-ce que run **tous** les tests **tout le temps** est une bonne id√©e ?
> On verra ensemble des techniques pour √©viter √ßa.

## poster main
Les good enough
==========
_"On teste que cette partie l√†, le reste c'est pas important"_
<img src="src/img/david-goodenough.png" style="object-position: top; min-height: 300px">
==========
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxx
==========

> #JP# Enfin, et c'est beaucoup plus rare, on a des √©quipes qui vont avoir une strat√©gie de test avec du focus.
> Ou avec une quantit√© de tests tr√®s limit√©e.
> Est-ce critiquable ? Est-ce que c'est une bonne id√©e ?
> $AC$ Clairement, on a souvent des √©quipes qui vont se concentrer sur des parties de leur codebase, souvent les plus critiques.
> On pourrait se dire que c'est une mauvaise id√©e, mais en fait c'est une strat√©gie qui peut √™tre tr√®s pertinente.

## poster main
Les good enough
==========
_"On teste que cette partie l√†, le reste c'est pas important"_
<img src="src/img/david-goodenough.png" style="object-position: top; min-height: 300px">
==========
xxxxxxxxxx
xxxxxxxxxx
Une approche pragmatique
xxxxxxxxxx
------
xxxxxxxxxx
xxxxxxxxxx
xxxxxxx
==========

> Cette vision pragmatique, si elle repose bien sur une analyse de risque, peut √™tre tr√®s pertinente.
> Si clairement on a peu de tests parce qu'on a la flemme o√π qu'on a pas le temps, c'est pas une bonne id√©e.
> Mais si on peut fragmenter son application, identifier les parties les plus critiques, les plus risqu√©es, et les tester en priorit√©.
> _Choisir c'est aussi renoncer_, si on choisi de ne pas tester certaines parties, c'est qu'on a fait le choix de ne pas les tester.
> C'est int√©ressant de creuser le pourquoi.

## ext-content 
<img src="src/img/is_it_worth_the_time_2x.png"/>
https://xkcd.com/1205/
<strong>XKCD 1205</strong>

> #JP# Automatiser des tests √ßa aura un certain cout, un certain temps, une certaine complexit√©.
> Vous connaissez peut-√™tre ce XKCD ?
> C'est une bande dessin√©e qui illustre bien cette probl√©matique.
> Passer des heures √† automatiser des tests sur une feature qui n'est pas importante pour vous, le business de votre entreprise, la codebase enti√®re.
> Est-ce toujours pertinent ?

## ext-content contain
<img src="src/img/gain_perte.jpg" />
Automate Within the sprint - <strong>Mike Cohn</strong>

> $AC$ Ces questions de co√ªt et de gain sur l'automatisation on se les pose depuis longtemps.
> Avec le temps, le cout de maintenance, de run d'un test automatis√© risque de d√©passer son gain.
> Mike Cohn dans son livre exposait d√©j√† son point de vue avec ce graphique.
> Pausons nous quelques secondes pour r√©fl√©chir √† ce qu'on a vu.

## text
Quoi en penser ?
<br/>
<br/>
ü§î
> $AC$ Bon, d'apr√®s ce sondage DIY il nous laisse l'impression que les dev ont pas tous en t√™te toutes les raisons et les b√©n√©fices qu'on tire du fait de tester.

## media contain white
<img onclick="this.src+=''" src="src/img/unzoom.gif"/>

> $AC$ En fait, si on d√©zoome et qu'on se demande **pourquoi** on teste, on compte 5 raisons de pourquoi on devrait automatiser des tests.

## kiosk
> #JP# On va vous faire participer un peu ! On va voir si on peut retrouver ensemble ces 5 motivations.
> Selon vous, pourquoi quelles sont les raisons qui nous poussent √† automatiser nos tests ?

> Rouge : Conformit√©
> On veut s'assurer que notre application respecte les sp√©cifications et les contraintes, etc. En bref, que le code, il r√©pond bien √† nos attentes.
> Que ce soit au moment du d√©veloppement comme apr√®s.
> Bleu : Documenter
> Les tests sont une forme de documentation, ils laissent une trace des comportements de notre code dans diff√©rentes situations.
> Tout ce dont on veut se souvenir.
> Magenta : Reproductibilit√©
> Les tests permettent de reproduire des comportements, de s'assurer que le code fonctionne toujours comme pr√©vu m√™me dans des cas complexes.
> Reproduire un parcours utilisateur complexe, ou bien impossible. Par exemple un disaster case, on a besoin de pouvoir tester
> mon code dans des conditions non triviales. _Echec de paiement_
> Jaune : Int√©grit√©
> Ils permettent d'assurer un √©tat stable de l'application, dans l'historique du code, dans les branches, dans les environnements, etc.
> **Observabilit√©** de l'√©tat de l'application. Feedback rapide de l'√©tat de l'application.
> Vert : Stabilit√©
> **Non-regression**
> Est-ce que le diff que j'apporte r√©pond bien √† tous les tests d√©j√† en place ? Est-ce que je casse pas quelque chose ? 
 
> $AC$ Pour nous voil√† les 5 raisons qui nous poussent √† √©crire des tests. Il faut garder √† l'esprit qu'on met en place
> tout √ßa pour acc√©lerer notre d√©veloppement. D'ailleurs, si vous sentez qu'un ou plusieurs de ces points sont des sujets
> dans vos projets, c'est peut-√™tre le moment pour voir s'il n'y pas un besoin de voir ou revoir la strat√©gie de vos tests.
> Si vous avez des tests qui :
> - ne d√©crivent pas votre produit: peut etre qu'ils sont trop li√©s √† l'impl√©mentation
> - ne sont fait qu'a la main: et vous en √©crivez par obligation
> - sont flaky: vous passez plus de temps √† les r√©parer qu'√† les √©crire
> - n'apportent aucune confiance

## poster main
Nos conseils
xxxxxxxxxx
xxxx
==========
Trucs et astuces
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
==========
xxxxxxxxxx
xxxxxxxxx
xxxxxxxxxx
xxxxxxxxx
xxxxxxxxxx
xxxxxxx
==========
> #JP# Pour r√©pondre aux diff√©rentes cat√©gories de gens qu'on a vu dans le sondage, on a quelques conseils √† vous donner.
> On rappelle qu'on n'est pas en mesure de vous donner des solutions miracles pour vos cas, juste des conseils.
> Il faut aussi garder en t√™te qu'on est des dev front javascript, donc on va vous donner des conseils qui sont orient√©s vers ce qu'on connait.

<!--
# pr√©senter nos recos: vitest / playwright
## believer (√ßa prend trop de temps)
C'est plus aussi vrai qu'avant
pour les tests unitaires -> vitest **REF** de l'article de Younes
pour les tests UI -> playwright -> **DEMO** d'un test facile
en plus c'est rapide -> **DEMO** playwright overhead
-->
## text
Pour les <strong>believers</strong>

> $AC$ Pour les believers, qui par _manque de temps_ ne testent pas, peut-√™tre qu'ils pourraient b√©n√©ficier de se reposer la question.
> Il faut voir dans leurs arguments quels sont les freins, si c'est √† la conception qu'on ne pr√©voit pas le temps de tester.
> Ou bien si c'est la mise en place de la stack de tests qui semble trop longue et compliqu√©e aux premiers abords.
> Ou encore si c'est la maintenance des tests qui semble trop lourde.
> A ceux-l√†, on conseillerait de se pencher sur des outils modernes qui viennent en r√©ponse aux probl√®mes de lenteur et de complexit√©.

## text
Vitest

> #JP# On pense notamment √† des outils comme Vitest, qui permettent de lancer des tests unitaires tr√®s rapidement avec une facilit√© d√©concertante.
> Pour ceux qui ont d√©j√† entendu parler de Jest, il s'agit d'un outil qui se veut √™tre son successeur.
> Il est rapide, simple, bien document√©. 
> Une migration de Jest √† Vitest pourrait √™tre une bonne id√©e, mais pas n√©cessaire.
> Par contre pour tous ceux qui d√©marrent de rien, on d√©conseille de partir sur Jest plut√¥t que sur Vitest. 
> Ce seront des tests qui seront proche du code avec une facilit√© de maintenance et qui offrent un feedback rapide.

## ext-content contain
<img src="src/img/marmicode_vitest.png">
Why Vitest? - <strong>Younes "Marmicode" Jaaidi</strong>

> $AC$ On vous conseille de regarder l'article de Marmicode sur Vitest, il explique tr√®s bien pourquoi il a fait le choix de cet outil.
> Sur son blog, vous trouverez des articles tr√®s int√©ressants sur les tests et notamment sur la migration de Jest √† Vitest.
> Il faut voir que c'est une commande pour l'installer et une commande pour l'initialiser et hop, on est pr√™t √† tester.
> Pour les tests d'interfaces, ou un peu plus _wide_ on vous recommande...

## text
Playwright

> #JP# Playwright, c'est le petit fr√®re de Cypress, derri√®re lequel se cache Microsoft.
> C'est un outil qui contrairement √† Cypress, √† pas un mod√®le √©conomique qui veut vos sous.
> Il a beaucoup de fonctionnalit√©s, qui peuvent couvrir la plupart de vos cas d'usages.
> Mais surtout, il est d'une simplicit√© d√©concertante √† mettre en place par rapport √† ce qu'on peut penser.
> La aussi, en 2 temps 3 mouvements, vous avez un test qui tourne.

## code
```js
  test(`can fetch with 100ms delay`, async ({ page }) => {
    await page.goto(`http://localhost:3000/100`);
    const response = page.waitForResponse(/api/);
    await page.getByRole("button").click();
    await response;
    await expect(page.getByTitle("status")).toHaveText("Request successful!");
});
```
on fait un test simple

## code
```js
[0, 100, 200, 400, 800, 1600, 3200, 6400, 12800].forEach((delay) => {
    test(`can fetch with ${delay}ms delay`, async ({ page }) => {
        await page.goto(`http://localhost:3000/${delay}`);
        const response = page.waitForResponse(/api/);
        await page.getByRole("button").click();
        await response;
        await expect(page.getByTitle("status")).toHaveText("Request successful!");
    });
});
```
on montre qu'on peut le param√©trer

## demo
faire la d√©mo de playwright overhead


<!--
## technophile (on fait du jest, du cypress...)
On teste des usages, des comportements pas des outils
Privil√©gier les happy path
üöö Mettez du lint dans vos tests
BDD / ATDD
-->

## text
Pour les <strong>technophiles</strong>

> $AC$ Pour les technophiles, qui ont une strat√©gie de test tr√®s orient√©e outils, on leur conseillerait de se poser la question de ce qu'ils testent.
> La tendance dans les outils de tests refl√®te ce qu'on recommande √† savoir tester des usages et pas des outils.
> On va recommander de tester qu'un utilisateur peut faire un clic sur votre bouton, pas que la fonction click de votre librairie est bien appel√©e.

## text
Happy path
> $AC$ Regardez du c√¥t√© des happy path, des parcours utilisateurs les plus simples. 
> Les cas √† la marge, c'est bien, mais c'est souvent l√† qu'on a des tests flaky, chers √† maintenir.
> Et c'est pas souvent l√† o√π la valeur business est la plus grande.

## text
BDD / ATDD
expliquer que le code r√©pond √† des comportements, et ces comportements peuvent √™tre d√©finis par des _acceptances_.

## tip
<strong>Soigne ta <em>testbase</em></strong> comme ta codebase

## ext-content
<img src="src/img/how-you-do-one-thing.webp">
<h3 style="width:100%">"How you do anything is how you do everything" - Le m√©chant dans <strong>John Wick 4</strong></h3>

> #JP# Si vous aimez vos outils et votre code, alors donner autant d'amour √† votre testbase qu'√† votre codebase.
> Tout d'abord par souci de coh√©rence, mais surtout parce que quand on y r√©fl√©chit un peu, on devrait avoir les m√™mes contraintes dans une testbase que dans une codebase.
> √Ä savoir, le code des tests doit √™tre lu, compris, maintenu dans le temps.

## code
```js
describe('foo', () => {
  it('should do bar', () => {});
  it('should do bar', () => {}); // Has the same title as the previous test

  describe('baz', () => {
    // ...
  });
});
```

> $AC$ Si on ne se fixe pas de r√®gle, on peut vite se retrouver avec des tests qui se ressemblent, qui se dupliquent, qui ne sont pas maintenables.
> Comme ici !
> Il existe pl√©thore de r√®gles de lint pour les tests, pour les noms de tests, pour les expect, pour les describe, etc.
> Si ces r√®gles ont √©t√© mises en place, c'est pour faire faces aux erreurs les plus courantes.
> Sachez que pour Eslint, l'outil de lint en JS le plus connu, il existe des tas.


## ext-content contain
<img src="src/img/expect-expect-light.png">
Le readme dans le repo <strong>eslint-plugin-vitest</strong>

> $AC$ Ma pr√©f√©r√©e √©tant la r√®gle `expect-expect` de eslint-plugin-vitest.
> Qui v√©rifie que pour chaque test, on v√©rifie bien au moins quelque chose ;)

<!--
## sceptique (on teste tout, coverage √† 100%)
Mutation testing au lieu de coverage
> Cool pour les juniors
üöö nx affected

## good enough (on test que ce qui est critique)
Reprendre les raisons de pourquoi on teste et voir les frictions
Et voir avec les piliers qu'on a vu si la strat√©gie en place est pertinente 
Vous subissez mais vous avez une strat√©gie

## pour tout le monde 

Avoir un testing.md
Mettre √† plat, ce que vous testez, comment, comment vous r√©pondez aux diff√©rents piliers.
Bon pour l'onboarding, pour la maintenance

**TEMPLATE** d'un fichier qui r√©pond aux questions

# Conclusion
c'est de la triche mais on a pas de solution miracle pour vous tous
rien n'est dogmatique
√† vous de cook
√©tablissez votre strat√©gie

-->
> #JP# Dans les conseils qu'on peut vous donner pour concevoir une strat√©gie de test, voil√† quelques id√©es et astuces qu'on peut vous donner.

## tip
N'objectivez pas le <strong>coverage</strong>

> $AC$ "N'objectivez pas le coverage". Le coverage pour rappel, c'est le ratio de ligne ex√©cut√©e lors de vos tests. Ca ne mesure en rien la qualit√© de vos tests.

## code
```js
function add(a, b) {
  return a + b;
}

it('should add two numbers and return the result', () => {
    const firstNumber = 1;
    const secondNumber = 2;
    let result = add(firstNumber, secondNumber);
});
```
> #JP# Regarde Antoine, j'ai trouv√© un code avec 100% de coverage. 
> C'est trop bien, mais l√†, il y a un souci √©vident non ?
> _solicitation du public_
> $AC$ Oui, il n'y a aucun expect. On a 100% de coverage mais on a pas de test.
> #JP# Une mesure quantitative ne peut pas se soustraire d'une mesure qualitative si on veut garder du sens. 
> Un principe int√©ressant pour compl√©ter l'analyse de coverage, c'est le mutation testing. 
> L'id√©e en deux phrases, c'est de modifier le code source et de voir si les tests √©chouent.

## ext-content contain
<img src="src/img/strykerJS.png">
https://stryker-mutator.io/
Optez pour du <strong>mutation testing</strong>

> #JP# Si les tests passent m√™me avec des modifications dans votre code, alors ce sont des tests inutiles.
> $AC$ Le sujet en lui est tr√®s vaste et on aurait pu passer la conf√©rence enti√®re dessus. On vous invite √† regarder des outils comme Stryker, PIT, etc.

## ext-content
<img src="src/img/mutationtesting.jpg"/>
https://www.youtube.com/watch?v=297tyPsXOm8
Mutation Testing - <strong>Lo√Øc Knuchel</strong>

> $AC$ Voil√† une conf√©rence que je recommande sur le mutation testing si vous voulez creuser c'est un sujet tr√®s int√©ressant

## tip
Ciblez les tests que vos changements impacts
todo: reword 
on aura des effets de bords de temps en temps, mais le temps gagn√© vaut le coup de ne pas lancer toute la boucle de test √† chaque fois
> #JP# On a parl√© de qualit√© de test, parlons maintenant de la quantit√©.
> L'important, c'est d'avoir une feedback loop la plus courte possible.
> Un bon moyen de gagner du temps sur la CI est de r√©duire la quantit√© de test qu'on run √† chaque fois.
> L'id√©e est de ne faire tourner que les tests du code que vous avez chang√© sans faire tourner le reste.
> Parce que...

## text
<i>Le test le plus rapide, c'est celui qu'on ne <strong>lance pas</strong></i>

> #JP# _le test le plus rapide, c'est celui qu'on ne lance pas_.
> Si votre architecture le permet, configurez votre projet pour qu'il ne run que les tests impact√©s par vos changements.
> $AC$ Les runners de tests, en tout cas c√¥t√© javascript, comme Jest et Vitest proposent des outils pour run les tests sur votre diff git.

## ext-content contain white
<img src="src/img/changed.png"/>
Le flag <strong>--changed</strong> de Vitest

> $AC$ Chez vitest, on a le flag `--changed` auquel on peut passer un hash de commit pour run les tests sur les fichiers qui diff√®rent depuis le HEAD. 

## ext-content contain white
<img src="src/img/nxaffected.png">
Nx affected project graph when <strong>lib10</strong> is changed - Nx docs
todo: reword nx est un exemple

> #JP# Dans un contexte _monorepo_, les outils de gestions permettent de run les tests sur les modules impact√©s par vos changements. Ici, on a `nx affected`....
> Si on fait une modif dans le module "lib10", on va run les tests de "lib10" et des modules qui d√©pendent de "lib10", mais pas les autres.


## poster main
Merci beaucoup !
==========
Oubliez pas de donner du feedback !
xxxxxxxxxx
xxxxxxxxxx
xxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxx
==========
xxxxxxxxxx
xxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxxxxxxx
xxxxx
==========
<img class="contain" src="src/img/qrcode.png"/>
==========
> @00:45:00@

## credits

R√©f√©rences :

* D√©p√¥t de la pr√©sentation : https://github.com/jpoissonnet/talk-test/

Liens :
* state of js : https://stateofjs.com/en-US
* Alister B Scott, Ice Cream model : https://alisterscott.github.io/TestingPyramids.html

* Designing a Pragmatic Testing Strategy : https://cookbook.marmicode.io/angular/pragmatic-testing-strategy/
Images :

* photos des parapluie : https://www.neyrat.fr/
* pyramide des tests 1 : https://thumbs.dreamstime.com/b/pyramide-de-test-avec-interface-utilisateur-tests-d-int%C3%A9gration-et-unitaires-essai-vecteur-unitaire-282317017.jpg
* pyramide des tests 2 : https://blog.atinternet.com/wp-content/uploads/2020/06/ROI-test.jpg
* pyramide des tests 3 : https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IA6N133_wkTin6DMq30u0w.png
* mike cohn : https://upload.wikimedia.org/wikipedia/commons/a/ac/WEB_RES-Mike_Cohn-%C2%A9-2016-Hows_Your_Headshot-6.jpg
* image de chantier : https://unsplash.com/fr/photos/homme-en-veste-grise-et-orange-tenant-un-appareil-photo-reflex-numerique-vert-et-noir-pendant-la-journee-wq7oyx_Kx-4
* m√©chant de john wick : https://villains.fandom.com/wiki/Marquis_de_Gramont?file=F6iIyvDbMAAqS8A.jpg
* Nx affected graph : https://nx.dev/ci/features/affected#run-only-tasks-affected-by-a-pr

Polices :

* Yanone Kaffeesatz : https://fonts.google.com/specimen/Yanone+Kaffeesatz
* Just Another Hand : https://fonts.google.com/specimen/Just+Another+Hand
* Boogaloo : https://fonts.google.com/specimen/Boogaloo
* Interstate : https://fonts.adobe.com/fonts/interstate
* Sufler : https://www.dafontfree.io/sufler-font/
* OperatorMono : https://www.typography.com/blog/introducing-operator

Remerciements :

* Hubert Sablonni√®re : pour lui m√™me et ses outils hyper pratiques pour les slides
* Jules : pour sa patience et sa pers√©v√©rance malgr√© ses cours en parall√®le
* Antoine : pour sa bienveillance √† toute √©preuve
